---
{"dg-publish":true,"permalink":"/projects/dallas-confluent-practice/notes/kafka-connect-202403301639/","tags":["üìñ","‚ô£Ô∏è/kafka"],"created":"2024-03-31T08:14:48.612+01:00","updated":"2024-06-12T17:03:29.756+01:00"}
---

# Kafka Connect

Solves external source to [[Kafka\|Kafka]] and [[Kafka\|Kafka]] to an external sink.

## References


## Flashcards

What is the connect-status topic?:: Helps to elect leaders for connect
<!--SR:!2024-06-15,4,210-->

What is the connect-configs topic?:: Stores configuration
<!--SR:!2024-06-19,13,290-->

What is the connect-offsets topic?:: Store source offsets for source connectors
<!--SR:!2024-06-21,15,290-->

When using plain JSON data with Connect, you see the following error message: org.apache.kafka.connect.errors.DataException: JsonDeserializer with schemas.enable requires "schema" and "payload" fields and may not contain additional fields. How will you fix the error?:: Set key.converter.schemas.enable and value.converter.schemas.enable to false
<!--SR:!2024-06-16,5,248-->

To continuously export data from Kafka into a target database, I should use:: Kafka Connect Sink is used to export data from Kafka to external databases and Kafka Connect Source is used to import from external databases into Kafka.
<!--SR:!2024-06-16,4,273-->