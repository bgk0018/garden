---
{"dg-publish":true,"permalink":"/projects/dallas-confluent-practice/notes/message-batch-202412231033/","tags":["â™£ï¸/kafka","ğŸ“–"],"created":"2024-12-23T19:57:48.407-06:00","updated":"2024-12-24T22:41:00.176-06:00"}
---


# Content

Batching is a way to increase [[projects/Dallas Confluent Practice/Notes/Message Throughput - 202412231035\|Message Throughput]] by increasing [[projects/Dallas Confluent Practice/Notes/Message Latency - 202412231035\|Message Latency]].

# References


<div class="transclusion internal-embed is-loaded"><a class="markdown-embed-link" href="/reference/kafka-the-definitive-guide-v2-highlights/#ref-745647007" aria-label="Open link"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon lucide-link"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a><div class="markdown-embed">



>[!QUOTE]  
>A batch is just a collection of messages, all of which are being produced to the same topic and partition. An indiâ€ vidual round trip across the network for each message would result in excessive overâ€ head, and collecting messages together into a batch reduces this. Of course, this is a trade-off between latency and throughput: the larger the batches, the more messages that can be handled per unit of time, but the longer it takes an individual message to propagate (PageÂ 5) #âœ‚ï¸  

</div></div>


# Flashcards
