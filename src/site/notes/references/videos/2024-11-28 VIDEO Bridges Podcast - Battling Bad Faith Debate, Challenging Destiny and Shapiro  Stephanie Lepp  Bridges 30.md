---
{"dg-publish":true,"permalink":"/references/videos/2024-11-28-video-bridges-podcast-battling-bad-faith-debate-challenging-destiny-and-shapiro-stephanie-lepp-bridges-30/","title":"Battling Bad Faith Debate, Challenging Destiny and Shapiro | Stephanie Lepp | Bridges #30","tags":["ðŸŽ¥"],"created":"2025-02-24T16:09:17.499-06:00","updated":"2025-01-02T23:02:32.031-06:00"}
---


# Battling Bad Faith Debate, Challenging Destiny and Shapiro | Stephanie Lepp | Bridges #30

>[!summary]- Description
> If you like the show and want to support it more directly, please check out our Patreon. 
https://www.patreon.com/BridgesStudio

00:00 - Start

01:00 - Introducing Stephanie Lepp and Philosophical Foundations

07:00 - The Anti-Debate: Redefining Political Dialogue

13:00 - Challenges in Constructive Dialogue

21:00 - Realignment and Polarization in Politics

28:00 - Synthesis in Action: Ethical and Political Challenges

39:00 - Philosophical and Psychological Tools for Growth

47:00 - Future Directions and the Value of Synthesis

50:00 - Practical Insights for Productive Conversations

58:00 - Balancing Convictions and Adaptability

1:06:00 - The Role of Moderation and Structure in Debates

1:14:00 - Lessons from High-Profile Conversations

1:26:00 - Media, Polarization, and the Path Forward

1:36:00 - Tools for Epistemic Humility and Better Understanding

1:48:00 - Closing Thoughts and Aspirations

Thank you@Resuvonia for the timestamps

In this episode of Bridges, Steven chats with Stephanie Lepp, an artist and strategist focused on thoughtful dialogue. They talk about what drives good conversations and how to make them better, both online and offline.

Stephanie shares tips on navigating spaces that often encourage conflict over understanding, while Steven talks about the ups and downs of trying to create meaningful discussions. If you're interested in getting better at talking with others or just curious about what makes conversations work, this episode is for you.

Tune in to hear how we can all make conversations a little better, one discussion at a time.

- Twitter: @stephlepp https://twitter.com/stephlepp
- Substack: Faces of X https://www.facesofx.org/

Hosts:

https://www.youtube.com/@destiny

https://www.youtube.com/@notsoErudite

Editor:

https://www.youtube.com/@sulack -

## Transcript

## Start

0:00

well first of all do you agree to the terms if not you don't get to participate and if you do and you're

0:05

doing all these engaging in bad faith you're you're just going to lose wouldn't it be amazing to walk away from

0:12

a debate with a better understanding all of us of the issue being debated about

0:18

Democrats think that only 30% of Republicans support sensible gun control

0:23

it's something like 70% sure and Democrats and Republicans think that like 50% of the other side thinks

0:31

violence is Justified and it's only like 5% it's like we're basically fighting with mirages you think that you're

0:38

bringing people from the left and the right together but it's because the left and right beliefs you have are very

0:43

Outer Perimeter beliefs but you are actually wholly unified in your anti-establishment beliefs I understand

0:50

a theory how that works but I actually just kind of feel like the most disliked by everybody but thanks for the no but you're you're probably Le you're less

0:56

disliked than somebody that they really hate no yeah that's probably true yeah

## Introducing Stephanie Lepp and Philosophical Foundations

1:01

so hey guys what's up welcome to another episode of bridges I am joined today by Stephanie LEP producer and Storyteller

1:09

and perhaps a radical Centrist that I'm about to do battle with on the both siding of all political issues cist so

1:16

that might be hard but we'll see where we land yeah yeah yeah yeah no well that that's an important kind of um thing to

1:23

talk through so we'll get there we'll get there um what do you what's your background in this world I guess in this

1:32

world this world if you were catching somebody up uh from my world who is in the online political horrible space yeah

1:38

um I would um I can tell a personal story that story yeah so um my first my

1:47

first kind of real experience with political activism was um completely alienating I

1:55

was a freshman in college I was a freshman at Stanford and I joined the

2:00

Redwood action team at Stanford acronym rats for a city council meeting in

2:06

mesino to protest the logging of the northern California redwoods and um at

2:11

the time an activist named Julia butterfly Hill some of your people in your audience might remember her was

2:17

living in one of those redwoods right so we get to the protest oh my God I know yeah you remember her yeah she lived in a tree for like days for almost two

2:24

years so we called her you know to her tree you know on speaker phone on mobile

2:30

phone and she gives us this pep talk and it's all very exciting um but I noticed

2:35

something strange well I noticed two things actually the first thing I noticed was that the people who we were

2:40

protesting against just looked like these were the loggers and their families just looked like very humble

2:46

people right they were mostly migrant workers from Mexico and I just I just thought to I remember thinking to myself

2:52

like I don't really want to be on the opposite side from those people you know I want to be on the same side as the

2:58

trees and the people you know the way these Lin I didn't know anything about sustainable development at the time but

3:03

I knew enough to know like the way these lines are drawn just does not make sense to me so that was like one observ and

3:09

that that kind of confusion marked the end of my involvement with rats and really politics for a while and the

3:15

beginning of a fascination with I don't know what I would have called it at the time but what I could Now call

3:21

integrating different perspectives that was one observation I guess I might as well just mention the second one because

3:27

it is also relevant to how I the second thing I noticed was we go in we go in

3:32

and um to the city council meeting and the spokesperson from rats is testifying right to the city council and he's

3:38

talking all about you know like the endangered spotted salamander and the

3:44

endangered owl and all these you know endangered species that you know are going to die if the Redwoods are logged

3:50

and I'm looking over at the city council members and their eyes are just glazed over like they've heard this a million

3:56

times I can tell and um and I I remember thinking to myself like

4:03

this is not changing their minds you know I don't know what would change their minds but I know it's not this so

4:10

I kind of came out of that experience with this question of like how do we redraw the lines to get more of us on

4:17

the same side of things and it's like how do people actually change their

4:22

hearts and Minds yeah okay so nothing like some good political activism to to alien and

4:30

inspire me to ask bigger questions yes yeah when you're looking at or or from

4:36

there um yeah catch us up to from there I ended up going into um philosophy and

4:43

dance and uh I mean that's what I studied my my I studied uh it's a it's a

4:49

word it's a it's a mouthful the name of the field is called science technology and Society it's actually just

4:55

philosophy and sociology of Technology interesting okay it was very interesting it was great well I I went into

5:01

philosophy because I wanted to do philosophy and once I got in there I found out that all you do is like study

5:06

other people's philosophies and maybe like like Tinker with like some like little detail of their and I was like where do I go where I got to make it um

5:14

and so philosophy of technology is is like a newer and and like for obvious

5:20

reasons like evolving realm of philosophy so that's what I ended up going into okay was this

5:25

like a master's program or for undergrad undergrad is undergrad that's cool yeah yeah it took me a long time to

5:33

understand although you probably could have seen it very clearly if you were like paying attention to me or if I had

5:38

been paying attention to the things that I actually enjoyed that storytelling I mean and honestly it's it's like I'm in

5:44

media but sure but media I what I'm interested in is ideas more than

5:50

anything else media just happens to be a vehicle through which I can share and communicate ideas I I don't I don't I

5:57

wouldn't call myself like a like like a film person or like a you know I happen to make I happen to work with video I

6:03

happen to work with audio I work with stories but more than anything else I'm I'm working with ideas okay

6:10

yeah when you um so okay so today what would you say your main I guess mission

6:16

statement is I know that Kyla and a few other people um pick this out because I'm personally going through it's a it's

6:23

very difficult to balance you know you talked about like who's on both sides of an issue like how much leeway do you give to somebody um yeah yeah where uh

6:32

where where is um my brain is half all

6:38

good I'm be honest this is not coffee this is hot chocolate okay oh how nice I

6:44

love that you know it's funny it's funny that it's hot chocolate because at first I was like damn that's a lot of coffee but now that I know it's hot chocolate

6:50

it's like what a sweet gift you're giving yourself in the morning don't my mom gets that size of a caramel

6:55

macchiato with extra extra extra caramel no joke okay so it's just her excuse for having a melted Snickers bar in the

## The Anti-Debate: Redefining Political Dialogue

7:02

morning and calling it coffee so it's basically the same yeah do you um when

7:07

you're looking at um when you're looking at political issues today and you're seeing people on different sides of a

7:13

political issue yes um I guess what's your approach to figuring out like how

7:18

much should somebody moderate an opinion how much should you try to like meet somebody in the middle are there some issues that are like non-negotiables I

7:24

guess how do you approach that yeah so well I guess um maybe it's worth kind of

7:31

um elaborating a little bit with like I'm coming from one of the places I come

7:37

from I could say is is is synthesis in the hegelian sense right and the idea very simply is just you have one idea a

7:45

thesis you have an opposing idea and antithesis and then you attempt to integrate them into some kind of like

7:51

higher order or more complex view a synthesis right and we could use a

7:58

metaphor and then I'll disting wish it from both sides of them and but but there are many metaphors I use one of

8:04

them is uh which actually sounds like both sides ISM but I'm just going to use it anyway one of them is is Parallax

8:10

View Vision right like what we see out of our left eye is slightly different than what we see out of our right eye

8:16

they're both true but partial but it's only by looking through both eyes together that the world goes from Flat

8:23

to 3D right so we gain depth that's not to say that like both ey in this case yes both eyes are like equally right

8:30

um but there are other metaphors that maybe get but that's that's kind of the the sense is you're is you're you're

8:35

integrating the different perspectives in order to gain a more comprehensive view now synthesis does get confused

8:44

with bothsidesism right both sides ism is the idea that all perspectives are

8:50

equally relevant or valuable right it also gets confused with centrism but

8:57

centrism is just kind of like the halfway point between the extremes which means you're letting yourself be defined

9:03

by the extremes right the way that I that I kind of like to explain the distinction is that it's it's unlikely

9:10

that one side is entirely right right that's tribalism it's also probably unlikely that all sides are equally

9:16

right right that's both sides ISM it's also probably unlikely that what's right is just like right in the middle of what

9:23

everyone is saying what's most likely is that most of us are partially right and

9:29

some of us are more right than others which doesn't make for a great tagline but that's kind of what's up when you're

9:35

contending with the full complexity of reality or of whatever issue you happen to be focused on yeah

9:42

for that past thing that you just said of all the people that identify as like Centrist or moderate how many do you

9:47

think have that particular point of view I don't know okay I would say like almost nobody yeah I would yeah I would

9:54

say and I would and like I don't mean to and by the way synthesis itself can totally be weaponized it's not like

9:59

synthesis is the end all be all answer we can and we can talk about how it gets weaponized but um with cism I don't mean

10:07

to totally dunk on you know it's like I think of centrism as kind of like training wheels like if you're so on one

10:13

side of things yeah like probably it's a good exercise to force yourself to try to just like articulate a Centrist

10:20

position but in the sense of like in the sense of training wheels like once you're pretty balanced you can let go of

10:26

the training wheels and just go for as much complexity as you can handle mhm

10:31

right I think um I I don't know why I think I I stumbled into a lot of just

10:37

very useful epistemic tools when I was uh in high school um I went from I grew

10:43

up very Catholic went to a Catholic grade school then I went to a Jesuit Catholic High School and at some point

10:48

15 to 17 I kind of become atheist and in that transitionary period um are you

10:54

familiar with uh with Ein Rand mhm so I end up reading um and then I read Atlas

11:00

Shrugged and for probably 6 to 12 months I'm just like full on like oh my God this is great like I've you know this is

11:07

the solution to all of philosophy and all of ethics and it's just this is amazing um and then at some point I

11:12

think I think it was like just as my senior year of high school starts I have this like feeling I'm like okay I went

11:17

from being Catholic with no choice of my own because I just grew up into it and then the very first philosopher that I

11:23

picked up I wholly fell in love with their philosophy and just became completely totally taken by it and I'm

11:28

like geez maybe I'm just like very easily influenced okay and one of the one of the things I guess Revelations I

11:35

had was that it's not good to be controlled 100% by somebody to have no

11:40

um subject object yeah or to have no like normative auton autonomy like I

11:45

have no foundation for my own like ethical or um ontological understanding of any part of the world right I'm just

11:52

buying it into somebody else's but it is equally as bad to be like to Define

11:57

yourself as the opposite of that totally yeah totally and yeah there's a really hard time I think when I argue with

12:04

people or when I tell people you know I can tell when somebody is like how do you feel about you know the FDA or how

12:11

do you feel about um uh I guess like Dei or anti wokeism or whatever like it

12:17

applies to both sides of people this isn't like unique to one group but yeah somebody will give me an opinion it's like oh okay I understand if this person

12:23

says this thing you're going to believe the exact opposite of whatever that is and you're letting yourself be defined by the precise thing that you say you're

12:29

against yeah exactly yeah yeah and often the first step I mean this is something I learned I used to produce a podcast

12:34

called reckonings which is all about how people expand their World Views every

12:40

story every episode tells the story of someone who had some kind of worldview transformation and often the first step

12:46

we go in is 180 degrees in the opposite direction right that's like the it's like okay it's not this so therefore let me just go 180 degrees in and and then

12:53

you're like wait a second there are 360Â° in this circle and you're like well maybe this isn't even a ccle maybe it's

12:59

a sphere and then you're like I don't even know what this is whatever it is I want to explore it and get to know it

## Challenges in Constructive Dialogue

13:05

more intimately but yeah the first step can sometimes be 180 but ideally you

13:10

like you you maybe only have to do 180 once or twice in order to kind of get

13:16

the get the sense that there is a bigger picture Dimension yeah yeah one of the

13:21

things I've been doing a lot um recently because my it feels weird to say special

13:27

toer career but I guess I do on online I do debate basically yeah and broadly

13:33

speaking I'm engaged in I guess like rhetoric like my goal is I think I have better ideas I would like to convince as

13:39

many people to believe my ideas as possible and there's this whole um there's this whole world of depending on

13:47

who I'm talking to depending on what we're talking about and then depending on what the platform we're on is is

13:53

going to change my approach to how I have that conversation basically right and especially over the past like year

13:58

or two years um I've I've tried a lot to uh like map out like why do people

14:04

believe the things that they believe and it's very difficult because yeah because people people will use words or say

14:10

things that are a proxy for something else they might not realize it I don't realize it often times um how do you

14:17

think what do you think are the major driving forces behind like how people arrive at their particular political

14:22

Persuasions or opinions or I guess other opinions like that I mean it's often it's like how

14:30

people arrive it's like their entire life story basically I mean when I used

14:35

to you know produced this and granted reckonings wasn't like a scientific

14:41

investigation but I racked up somewhere around 200 hours of interviews with people who you know was like deeply

14:47

conservative congressman who made what he would call a spiritual conversion on climate change and stayed conservative

14:54

but all the way to um you know the architect of Facebook B's business model

15:00

who realized he was addicted to his phone had a reckoning and has since devoted his life to tackling technology

15:05

addiction all the way to former white supremacist who transcended a life of violence all but always it's like how

15:12

did you you know it's it's a it's it's it's it's it's your story too it's like I was raised Catholic and and I think

15:19

your mother is from Cuba I mean it's like it's it's your entire life story often that leads you and then sometimes

15:25

you'll have a like you had an IR Rand experience usually it's not information

15:30

that changes people's views because people often only trust information that confirms what they already believe but

15:36

um but I mean I can share you know I I used to have this highly unscientific

15:43

kind of running list of thing before I started the show because this was a question for me it's like how do people change how do you know I know it's like

15:50

I didn't even know what search term to Google it's like I know behavioral like am I am I looking for worldview

15:56

transformation is that even a thing like I know behavioral economics is a thing but I'm not looking to find out what

16:01

makes people floss their teeth more often you know so so anyway so I had this I had this like highly unscientific

16:07

list of things that I thought you know it's like falling in love near-death experiences you know birth of a first

16:12

child you know sometimes very rarely but sometimes information and what I what I learned over the course of interviewing

16:19

many people is that it's not it's not that those things make us change what

16:26

those things um what things like that have common or what they do is that they

16:31

reveal to us the difference between who we think we are and who we actually are

16:37

or the difference between the impact we think we're having on the world and the impact we're actually having on the

16:43

world and it's seeing that difference at seeing that Gap that initiates the process of transformation and I can be

16:50

more specific and go into specific stories but that that I mean I I guess I

16:55

should like if if you're talking to someone like at your Thanksgiving dinner table or who's actually basing their opinions

17:01

on information which is rare then you can use things like under what circumstances does what you're saying

17:08

not apply and they'll have an answer or like what would it take to change your position and they will hopefully have an

17:15

and if they don't have an answer then obviously then that's over you know but for the most part like you said like you kind you have to get into like

17:21

why why are people believing what they what is what is their goal what are their values and it's by getting into

17:28

that that that and and seeing maybe how they're not actually achieving the goal that they have that they profess to have

17:35

that can initiate a process of transformation mhm I think um one of the

17:41

more frustrating things that I uh kind of noticed is I feel like if if somebody were to say somebody has a strong

17:47

position and I would to ask why do you think that and they were to say you know I grew up this way my mom and dad told

17:53

me this um this is just like I've always been around this it's what makes most sense to me I think i' be okay with that

17:59

and okay that's good um but I think uh it's kind of an anti-western I guess way

18:06

of conceptualizing but but if I say we fetishize like scientism or information

18:11

too much and everybody wants to have this like oh well actually you know I'm very data driven and I arrived at my own

18:17

unique opinion whatever which I actually think is great I like that but I don't like it when people think that and that's not what's happened at all um

18:23

because it's harder to move somebody um or or even to make them aware of where their opinion comes from yeah and uh

18:30

I've noticed you've actually it's funny you've said two things so far usually when I'm talking to somebody to try to get a gauge of like how much do I think

18:35

this person has engaged to any level of you know like selfinterrogation of beliefs I'll ask somebody like oh how do

18:41

you know if you're correct on something and there are concrete specific answers

18:46

that you can give and then there are the platitudes and the platitudes are always like the aesthetic of oh I've thought

18:51

through this and then there two of the and I've said them no no you've said two of the concrete things um that I think

18:57

are really important one is uh you should be able to convincingly argue the other side of an argument yeah if you can't you have no understanding of your

19:03

own argument yeah um and then the second one um the second one is uh somebody

19:09

should be able to ask you what would it take to change your mind on this and if you can't even conceive of something and

19:14

it's very funny because I thought I was um at one point in life I thought I was very clever uh I was like oh my God like this is a good question to ask somebody

19:20

to really get them to think and I'd say about half the time it's like what would it take to change your mind on this someone just say nothing and like oh

19:26

you're honest at least you're honest I guess yeah like that's that's a crazy that's a crazy statement yeah mhm like

19:33

yeah yeah I I I find so yeah I guess the there's a frustrating aspect of

19:38

everybody thinks that they're more I guess discreet in arriving at their beliefs than they actually are and then

19:44

sometimes it's really hard to change people's minds because they um are unaware of how much their environment I

19:49

guess has influenced them on a particular thing mhm um if you're trying to change somebody's mind on a thing what are

19:56

things that you consider I guess that's very more I also don't I I I I mean I do

20:03

use the word change but I honestly think in terms of not not changing someone's

20:08

mind but expanding M it's like expanding the aperture like you're probably you

20:14

you might be locked into some like partial truth it's not to say it's not a it's probably part of the picture but

20:19

let's like expand the picture so yeah I I it's it's back to the like if it's

20:25

someone who you know is is is maybe you know basing their opinions on actual

20:30

information then those kinds of questions of under what circumstances does what you're saying not apply or

20:36

what would it take to change or like what are the negative po potential e

20:41

externalities or Consequences of what you're proposing like anything that gets or yeah how would you Steelman the

20:48

opposing perspective so any that's for people who are maybe like it's more information based but if it is coming

20:54

from a more um coming from a not as not as examined place of values then I just

## Realignment and Polarization in Politics

21:00

want to understand what they care the most about like what yeah what what are your what what is your goal what are you

21:06

the most interested in and then from there I think we can have a deeper conversation but um I don't know might

21:11

be interesting to get specific um I do happen to be working on right now a

21:18

project that is designing a format for debate so I would love to share that with you and then um the other yeah the

21:26

project that I just released which is actually how I like found you it was I just released a

21:31

video series that someone in your audience said you should start it's a series said proposed you as a potential

21:38

star for one in the series gotcha so um and they're very relevant to what we're

21:44

talking about so maybe it just helps things get more concrete you've done one of these on um on abortion is this you watched one of

21:51

them okay okay okay yeah um and it do it's basically just a so it's called

21:56

faces of X it's a series of short videos that integrates different perspectives

22:02

on culture War issues like abortion gender and race the format is very simple I use that hegelian Triad of

22:09

thesis antithesis synthesis it's the same person playing all three so it's the same person kind of Steel Manning

22:15

and wearing different outfits steel Manning the different sides and then synthesis walks in the door and attempts

22:20

to offer some kind of integrated or more comprehensive perspective um the series

22:27

stars kind of cultural influencers who are known as independent thinkers on these issues but ultimately the series

22:33

is not really about the issues it's ultimately about kind of cultivating our

22:38

capacity to integrate different perspectives and see reality in more

22:44

multi-dimensional way but in a way that is like short and like internet friendly

22:50

and simple so it it is it is it is it is somewhat like Pat in this like thesis

22:56

antithesis synthesis but it's ALS Al something that I think is pretty rare online to really see the different sides

23:02

like Faithfully well represented and then some kind of an attempt at

23:08

integration yeah when you're trying to synthesize two different points of view um do you find that this is often times

23:15

like trivial in so far as as long as people are willing to open their mind and consider something it's easy or do

23:21

no it's hard the both Sid ism is easy saying something like capitalism has upsides and downsides it's like great

23:26

thanks cool like what do I do with that but synthesis like it is it is I mean

23:33

many many philosophers have you know have written extensively about you know that it's an art and a science I can

23:39

just I can share three questions just just to kind of distill it I can share three questions that I

23:46

asked myself in the process of writing the scripts so one is and they are actually pretty simple but if you like

23:51

take them seriously it requires some thinking so one is is there an either or that can be flipped to a both and that's

23:59

one that can be helpful another is is there an opportunity to shift from

24:06

what's better X or Y to under what circumstances is X or Y

24:14

useful and then the third question is are there perverse incentives like the

24:21

incentive to maximize short-term profit or are there perverse incentives that if they were to be addressed would would

24:27

would help alleviate the debate like those questions if and th those might be

24:33

good questions to ask someone too if you're in a is like can help you find some kind of synthesis between the

24:40

different perspectives when you're um let's I guess let's pick an issue so that we can yeah we'll do something um

24:48

climate change great okay um so as applied here um your first question is

24:54

rather than either is there either or yeah so with climate it's something it's like it's the like economy versus

25:01

environment kind of a thing yeah one one side is the well the most extreme version of one side is all fossil fuels

25:07

need to be eliminated as soon as possible the other side is the sun changes our climate who cares just burn whatever um well and what are we going

25:14

to do like destroy our economy in the process so yeah so it's it's like it's obviously not one it's similar to the

25:20

covid lives versus livelihoods it's like it's not we're not going to choose one or the other right yeah we cannot

25:29

they they they need like these two things are in Dynamic co-evolution with each other the environment and our

25:35

economy so it's not like we're going to do one at the expense of the other so that's probably a simple a simple one

25:42

okay yeah the um under what circumstances oh yeah okay wait oh sorry

25:47

so for the first thing so you just did the either or rather than either or um both and both and okay yeah um the and

25:55

then the second one was is there an opportunity to shift from X or Y to under what circumstances X or Y um you

26:02

just brought up fossil fuels I think it'd be really nice to I haven't seen this done but I would love to see some

26:08

kind of Matrix that with like different energy sources it's like wind solar

26:14

fossil nuclear like all of them and it's and it's like under what circumstances if any and for some you might say none

26:23

there are some that and for others you might say use them until we don't need

26:28

use them anymore because something has been achieved or something like that so instead of it's like instead of like

26:34

renewal versus non-renewable it becomes and under what circumstances do we use which ones in pursuit of a goal and

26:41

maybe there are some that we are in Pro in process of trying to wean ourselves off of but we need them in order to get

26:48

to our ourselves to the place where we don't need them anymore so it's it's it's it's like a more

26:55

um Sy graduated yeah strategy okay yeah

27:00

and then the third Point incentives yeah so um for that for

27:07

climate yeah I mean the perverse incentive there is one one of them we

27:12

could just use the yeah the the incentive to maximize short-term profit is obviously getting in the way of you

27:20

know and were we to address like were we to eliminate the fiduciary duty let's

27:26

say would that would probably yeah if if if if like if public companies were not

27:32

held accountable to maximizing quarterly profits yeah that would probably like

27:38

free us up to address the climate issue much more easily because there would we

27:44

we wouldn't be up against these like seemingly tradeoffs that would no longer be there MH um and and and granted like

27:52

fiduciary duty like we could even go Upstream of that like what's Upstream of the fidu you know go all the way up to

27:58

as Upstream as you want to go but um and I would say it's it's more Upstream than capitalism but dealing with those

## Synthesis in Action: Ethical and Political Challenges

28:05

Upstream kind of perverse incentives would definitely help alleviate the climate debate okay yeah um I don't have

28:13

any of this in like my mind in terms of like a frame of how I function I guess like these particular terms but there's

28:20

um it's interesting because there are ways that um I've approached a lot of these using other language that that

28:26

I've just kind of like happened to stumble into to or make my way there um

28:31

one of the things that I talk to people about um that's very frustrating to me is I'll tell people don't get attached

28:37

to a process we really don't care you should be attached to the outcome like that's generally what our whatever

28:42

ethical framework is usually aimed at some particular thing um for instance if um some uh like if you believe that you

28:51

know we should maximize the well-being for as many people as possible and you think people shouldn't be homeless uh then you want to have people living in

28:57

homes uh and if you have some particular policy say rent control or something um

29:03

rent control is not the same as less homeless people if we were to discover that rent control doesn't help right

29:09

well then we would say okay well we ditch that and I noticed there's a lot of um

29:15

uh confusion of the strategy and the goal yeah normative normative coupling or normative confusion where you get

29:21

these people that will I say these people but it's like it's almost everybody where you have this like almost this like deontological obsession

29:28

attachment with like the process itself and sometimes it feels like it inhibits people's ability like if I were to ask

29:34

somebody some of these questions like the either or um versus the how can we incorporate this particular thing it it

29:42

feels like I'm asking somebody it feels like I'm rather than saying okay you think that this particular thing isn't

29:47

good but aren't there like maybe certain circumstances where it could be it feels like I'm asking somebody like when do you think it would be okay to murder

29:53

somebody like that's what it that's what it feels like the interpretation is they can't their interpretation yeah because

29:58

they can't um even fathom that there's some without um yeah you um I don't

30:04

think you realize how much you're hitting on so many of the frustrations I have with conversation right now because the like the if if somebody was even

30:11

expressing a lot of what you were saying just saying these things I would like okay we're ahead of like 95% of the

30:17

conversation right now the idea that we could even consider like you know hey green energy is good there are some drawbacks how do we move in this

30:22

direction rather than green energy oh so you want to control my \[ \_\_ \] life but but we already do it in other domains of

30:28

Our Lives you know like as parents I think parenting is is the perfect example it's like I love the \[ \_\_ \] out of

30:34

you and go the \[ \_\_ \] to sleep and those things just so deeply coexist which is

30:39

part of what kind of grows my heart and grows my mind as um as a parent right

30:45

and or with something like like you can take baby you can start with Michael Jackson that you know it's like how you

30:52

know do we continue listening to his what do we do with the like fact with the fact that he's like a spectacular

30:57

ular Entertainer and like likely a perpetrator of child sex abuse how do we hold those we do it with Thomas

31:03

Jefferson we do it all over the place I think so it's like maybe using you know and with with with Michael Jackson what

31:09

would be the synthesis on Michael Jackson it's like okay spectacular Entertainer likely perpetrator of child

31:16

sex abuse he was also the victim of abuse right and perhaps it's because he

31:21

was the victim of abuse that he became such a spectacular Entertainer and kind of a creep like maybe these things

31:27

actually go together so I think we we can start with we can give ourselves training wheels I think we we do already

31:33

do this we are able to hold dialectics in other domains of our lives and it's

31:38

just like showing us that we can do that I mean I shouldn't say just it's not like just as simple as but there is a

31:44

way in which I think we already know how to do this and it's just porting it into the realm of politics or into other more

31:52

challenging yeah I guess I feel like when it comes to politics um I apologize so much to any hegelian out there abuse

31:59

these words um but yeah it feels like uh what synthesis is when it comes to political issues for the vast majority

32:04

of people synthesis is actually just choosing whether you're going to eject

32:09

the um the what is the thesis versus the uh antithesis yeah it's like okay well which one of these am I totally ejecting

32:16

and then this is my that's my synthesis is this is actually fully evil or fully good and it's like okay well well I mean

32:23

I um my like absurdly idealistic take on that is that we you know these

32:29

dialectics actually need each other like Innovation and tradition like Innovation

32:34

is meaningless without tradition tradition is meaningless without innov like they actually need each other to

32:40

exist individual freedom and Collective responsibility need each other what

32:46

choice and life right like what is Choice without life what is life without so we have almost like perfectly split

32:52

ourselves into these like these dialectics that actually need each other in order to even exist and so my joke is

33:00

that we're actually like a an amazing marriage waiting to happen yeah once we

33:06

and and that's not that's not even like how much of this is it's not even

33:11

entirely our talking about perverse incentives so much of this is obviously driven by our information ecosystem

33:18

right the the social media business model that is designed to maximize engagement and how that all happens etc

33:24

etc we can go into that but so I yeah I I think um I think we're more capable of

33:30

this than our um than than social media would indicate I think um the it doesn't

33:36

necessarily uh maybe applying the same way here but the when it comes to incentives that's one of the things that

33:41

I um I try to stress to people when you're looking to see why a particular group of people is acting in a way or why people have a certain belief um

33:48

rather than starting with this okay well let's analyze you know does it make sense for somebody to think X I usually

33:53

just tell people like okay hold on what are what what would you be incentivized to think or feel here and if the incentives are wrong I would almost tell

34:00

somebody you should abandon whatever you're trying to do and change the incentives because the idea that you can have a misaligned incentive structure

34:06

tot and rely on people to just make the right choice over and over and over again it's is never totally work and if we look at the incentives that drive

34:12

social media totally it's like how could we even expect to have like the fact that we even have long form thoughtful

34:20

conversations podcasts the bridges podcast is like a testament to the fact that they're actually we are we are it's

34:26

a it's it's it's we are it's it's almost because we are we are like swimming upstream and the fact that those even

34:33

still exist and are growing in popularity yeah I think is a testament

34:39

to the fact that we actually do want like healthy food we want content that will help us grow yeah hopefully yeah

34:44

and then there's a lot of um there's a lot of issues because I realized um I went back and forth for a while between

34:50

like okay I think people are pretty smart to okay people are just \[ \_\_ \] stupid you just need all the guy and then and and now I'm more on you're at

34:56

the synthesis the synthesis yeah the synthesis is that people are incredibly smart but depending upon um what the

35:03

issue is you shut your brain off cont yeah totally and the context in which you're yeah and what the context is

35:09

designed to do okay so take a guess so the the person in your audience who um

35:14

proposed you for faces of X what um before I tell you what issue they suggested um what what issue would you

35:22

do you think you would um if you would you even be interested I guess is the first question in being um yeah being in

35:30

this video series if so what would be your issue if not what would have to change about the format um to make it

35:36

interesting to you broadly speaking something to do with mega that was not what the person said

35:42

but okay wait you would do faces of Maga could you do you feel like you could do a synthesis on

35:48

Maga would beol I actually hate um I know you do no no no no I hate doing the

35:53

um there's a joke in my uh community that at the end of a debate sometimes if the person is like a good moderator

35:59

he'll ask one person to steal man on the other side um and you don't like doing that no why because I'm not okay I'm a

36:07

really good debat I'm not trying to be I'm not trying to whatever myself okay but like if there's an issue that I can

36:12

debate really well I can always debate the other side really well of course because if you can't debate the other side you don't how could you possibly

36:17

know your own positionally um so it'll be very frustrating one of the big topics that I've done the past year has

36:22

been Israel Palestine and it'll be very frustrating that um you know they'll say like okay Can you steal man uh Steven's

36:29

argument or Ste man Destiny's argument and they'll say like uh well I guess it sounds like he's just saying that the

36:35

Palestinians have made mistakes so they deserve getting genocided and it'll be like okay Stephen can you st on their argument it's like yeah in 48 I can

36:42

understand why a bunch of people be upset that israelit came over and blah blah blah and it's was like okay and by the end of it obviously whatever Ste man construction of their AR it's going to

36:48

be better than the argument that they gave me like I know all of the like usually people aren even using the best Arguments for the so then I end up in

36:53

this stupid spot um where they just let that sit yeah now I feel like I like

36:59

validated the other side so much and I yeah so now when I whenever somebody says I was you go first and then I'm

37:05

going to give you a steel man that's as made of steel as the one that you give me because this is insane I think it makes you look better though it makes

37:11

you I think it validates your a little bit he really knows his \[ \_\_ \] to my

37:17

audience it does but sometimes to the other side they'll go like yeah obviously Steven's position is completely totally impossible but he was

37:22

able to steal other debate format that I'm designing he would lose points for that that's good you would actually give

37:28

him or not give him points for that yeah um wait what was what was the topic that the topic was free

37:34

speech okay yeah what do you think um would you

37:40

want to would you and we can we can we can we can like spitball a little bit right now if we want to but yeah it

37:46

would be you would be kind of articulating and simplifying because granted different issue many issues have

37:52

more than two perspectives M and there can be more than two characters before synthesis comes but thus far it's just

37:58

been simplified to two characters that are kind of going back and forth and then the synthesis comes in so yeah how

38:05

do you feel about um do you feel like you would want to kind of rep Faithfully represent the different sides of the

38:11

Free Speech debate and then try to yeah I could yeah I could absolutely do that I think it's a super fascinating

38:17

conversation yeah do you have a sense of what the synthesis would be um uh well yeah the synthesis is my

38:25

position obviously is it yeah well hopefully right obviously right hope you'd hope so right well I mean but for

38:32

I mean for for the people who are who were in the video we didn't it it wasn't it wasn't clear like from the beginning

38:38

exactly it took some going back and forth to kind of articulate what you

38:43

know like the star of faces of capitalism she actually had kind of a schizophrenic relationship with

38:49

capitalism okay so for her it was actually really helpful to kind of integrate those into something that was

38:55

but um some kind of a synthesis but I don't I don't actually feel like I fully know your position on Free Speech yeah

## Philosophical and Psychological Tools for Growth

39:02

yeah so there's um God I'm going to be so disappointed when I see your stuff later and I and I find out you're just

39:08

lying and crazy no I'm just kidding no there are so many times where I have a conversation somebody like oh my God they're checking so many of the right

39:13

boxes and then I'll see something like so this is why all progresses are evil woke tart you might find you will

39:19

probably find things you don't agree with and I'm okay things I don't agree with as long as I feel like they're considered like a person is there's a

39:26

considered approach like I don't agree with this but I understand where they're coming still and it's still a work in progress I mean My Views have changed

39:32

since the series I mean faces of X it's like the

39:37

synthesis a synthesis like a good synthesis then just becomes the new thesis true right in our evolving

39:44

understanding of reality so the synthesis in those videos is just where we happen to be literally on the

39:51

day we filmed like the script had been changing up until the second we filmed and then we filmed and then that's just

39:57

the snapshot in time so you will definitely find things that are less

40:02

considered because I am just hopefully growing in my consideration over time yeah there's like um I have strong

40:09

feelings about um vaccines and if I hear somebody say something like uh like oh well I don't think I want to put

40:15

anything like that on my body if I look at a person and if this person is like uh like I grow my own food I go to the

40:21

gym every day I do whatever and I I'll hear a statement on be like okay that's pretty dumb but you know okay okay but

40:27

if I hear somebody say you know like I wouldn't put that in my body and they weigh 350 lb they do recreational drugs

40:34

they smoke I'm like oh my God stop you know yeah so that yeah that's yeah in terms of like consistency is there like

40:39

a considered thing like something you thought about um there's something else that you um there's something else you

40:45

said and it's funny because you just said this is like a like an off-hand like a very basic question but it's a thing that would break probably 95% of

40:52

people's minds when you ask and it's can you give me like a negative of a thing that you're

40:58

a drawback um people are really bad at saying anything bad about a position

41:03

that they offer um and I think also sometimes people are really bad at um at uh at removing normative values from

41:10

things so like when I'm talking about um economics I usually encourage people like our our end we should have a lot of

41:16

normative value attached to the end like we want more people to be wealthy want people people be able to be less

41:22

homeless we want people to have like you know food whatever all of that um but the processes themselves should be

41:27

looked at IM morally or or without ethical like attachment right cuz something might be better or worse than

41:33

achieving some end but that doesn't mean we have to feel like it's morally good to be whatever yeah so getting somebody

41:38

to understand you mentioned F fiduciary responsibility right a firm's job is to

41:43

return profit to people that invest in it that's it I don't think that's a good thing I don't think it's a bad thing

41:49

that's just all it does in the case of a pharmaceutical company that discovers a medication that could save people's

41:54

lives um and makes money selling it that's really good in that case if they do that um in terms of a pharmaceutical

42:00

company that realizes they can save a whole bunch of money by cheating the phase three trials that's really bad

42:06

right so then the but the goal is to never you can't scold somebody and say don't do that you have to well what are

42:11

the incentives it's a firm they're trying to make a lot of money so you have things like um the NHS or the FDA

42:17

who says hey if you want to make money you have to play by these rules or else you're in big trouble so that they kind of stay within that rule set um yeah

42:24

it's very hard to get people to like take away the normative value of a particular thing and just kind of

42:29

analyze what it is and and then consider like what are the pros and cons of like the positions that you're advocating for yeah I agree kind of like to a point I

42:36

mean I agree in the sense that um I mean I cap I think capitalism is a perfect example of this it's like capitalism is

42:42

a strategy for achieving a goal capitalism is not the goal what is the

42:48

goal like that is an excellent question let's talk about the goal like what do we want our civilization to be able to

42:53

accomplish with the economic system we designed for ourselves but in in terms of like the agree to a point um there's

42:59

this I'm going to get nerdy for a second but I think you'll actually appreciate this um this tool I think I'm generally

43:06

quite jockish but I'll okay we be NY for a second I guess okay yeah go for it okay okay so this is a um something I

43:15

learned from Daniel Goldman he's an expert in emotional intelligence and I

43:20

think it was like this this he came out with this article it's like 10 years ago but so it's like every couple years

43:27

Harvard Business Review comes out with an article that's like the top 10 qualities of a good leader as if there's like one way to be a good leader and

43:34

what he did which is really interesting is he interviewed like hundreds of Business Leaders and he identified six

43:41

distinct leadership styles you don't have to like remember them all bici it's like commanding and then there's

43:47

affiliative and there's Democratic and Visionary whatever there's like six clusters of kind of like Styles and so

43:52

he identifies the different circumstances in which each sty works the best so

43:58

commanding is really helpful in a crisis to Kickstart some kind of a turnaround affiliative is really helpful when

44:05

people aren't getting along to like heal riffs on a team Visionary is really helpful when you need to go in an entirely New Direction whatever so but

44:12

he doesn't just stop there you could just say oh great then you could just like that's already a really helpful frame it's not like which leadership

44:17

style is the best but under which circumstances is which leadership style the most useful he also goes on to

44:23

identify the the like the the impact that each Style has on the organizational climate right so

44:29

commanding surprise surprise has a really negative impact because it feels like \[ \_\_ \] to be commanded affiliative

44:36

has a positive impact um you know like Visionary has a very so it's not just

44:41

descriptive it is actually also normative it's like and and you know it's like if I'm in a crisis I can say

44:46

to my team like hey team I'm going to shift into hardass mode for a second in order to get us out of the crisis so

44:53

that I don't have to be a hardass anymore it's like we use the less desirable strategy IES to get oursel

44:58

it's like the fossil fuels it's like the to get ourselves to a place where we don't need to use them anymore so we can't actually say we can't actually say

45:05

like there are some less desirable strategies there are ones that we'd rather use less and we only use them in

45:12

order to change the circumstance so that we don't have to use them anymore but

45:18

that obviously requires a like what's the goal what are our values what do we care about you know um but yeah so I I

45:26

would say it's not they're not only there are not only descriptive differences there are there may also be normative differences between different

45:33

but the normativity is always goal oriented not yeah process oriented yes yeah yeah um this uh the free speech

45:41

thing was is a is a thing that comes up a ton obviously and I fight a lot over with a lot of people so there's like um

45:47

in in a very crude form I guess your thesis and your antithesis is I'm curious yeah the thesis is that the most

45:53

amount of free speech is the best thing in the world the best idea has rise to the top um the marketplace of ideas like we just

45:59

need the most free speech possible um and then the antithesis is I guess if you think of an internal dialogue you

46:05

need one voice to so that you can move in One Direction so you can have like a like this is the correct answer um and

46:11

having a more Crackdown approach on it allows you to get rid of all the bad faith actors they can't hijack your

46:16

system you don't have all these stupid things you're wasting your time on and everybody can more efficiently just move in the correct direction um and both of

46:23

these ideas and it is impossible to go going back to what I said before nobody can admit the pros and cons of their

46:29

side both of these ideas have Merit obviously um in in a kind of ironic way

46:35

it just played out in that leadership thing that you talked about I don't know if this is true or not because I haven't studied Greek or Roman history but I

46:41

feel like there's like 20 movies that give an example of like when Rome was being invaded they would nominate one

46:46

man to make all the decisions or whatever right oh in a crisis yeah yeah exactly yeah and it's that idea of like

46:52

um the commanding leadership style right there are times when um freedom of speech

46:57

is awesome for a for a bunch of direct reasons and for a bunch of indirect reasons um indirect reasons that I'm

## Future Directions and the Value of Synthesis

47:03

still learning about uh there's a guy I uh Huey Lee um who lives actually near here and does a lot of videos on styles

47:10

of government everything and one thing that I didn't even consider when he was talking to about the benefits of democracy versus authoritarianism is

47:15

democracy actually gives you more information about what to do in an authoritarian regime if you're not sure

47:21

if the government isn't sure if they should move you know in One Direction or against it it's hard to know what they

47:27

should do because you don't actually know what the people are thinking but in a democracy you always know what the people think you're constantly voting on things oh okay freedom of speech um and

47:34

then on the other hand you have clearly and OB and no one will admit this you have obviously bad faith actors that are

47:41

leeching or abusing the freedom of speech system because I can just like tell lies with impunity and I have freedom of speech so it's okay um yeah

47:48

and it's very hard to reconcile the synthesises um I guess in my mind when I think of synthesis um the integration is

47:55

how can I get like the most pros from this part while minimizing the bads and like the most pros from this part while

48:01

minimizing the bad and like what is the thing that I have left leave the bath water take the baby as much as possible

48:07

yeah basically yeah yeah sounds good yeah sounds good but if I if I even hear somebody's engaging in that thought

48:13

process I'm already like okay that's cool I don't even care what your answer is like the fact that you've been thinking about it in this Frame I'm

48:18

already like super happy like you don't have this like I yeah like this deontological obsession with just like

48:24

one thing like fre spe is like a good it's nothing is ever it doesn't matter there's it's like dud well and I guess

48:29

well okay so let's um so let's do it okay let's do faces of free speech cool sure great if you want to yeah yeah um I

48:36

will say though now that we've like um I think it is probably worth um acknowledging that like anything

48:42

synthesis can be weaponized right if I want to convince you of something that's Center left I make the center the thesis

48:49

the left the antithesis and then Presto I've like you know so um oh actually I will ask you one more question then um

48:57

yeah how can it be weaponized or well so when you're engaging in um when you're

49:04

when you're integrating ideas yeah um sometimes I'll hear somebody say uh

49:11

this is my belief this is my axiomatic ethical belief on this particular thing

49:16

and then sometimes when they're given a thing to consider um I'll notice that in

49:22

having like two things they're they're deciding between one or the other and I'm some I'm trying to make people

49:27

understand when you're saying that you believe that um let's say that you believe that uh like freedom of speech

49:33

is always good okay freedom of speech is always good and then we'll take like a like a radical example uh child sexual

49:39

assault material or whatever right obviously you don't think this is okay right and it's like no okay and I try to make people understand that like okay

49:45

well you have a clear conflict here yeah you're appealing to something else

49:51

there's something else that's working more foundational than this your freedom of speech is a there's a second or third

49:56

belief there's something underneath because when I ask you about a thing you don't stop at freedom of speech you're considering something else and we have

## Practical Insights for Productive Conversations

50:02

to find out where that something else is when you're doing um integration into synthesis when you're doing this how do

50:10

you get people to understand what they're aiming towards because to to to

50:16

even consider two ideas you must be comparing them to some kind of internal system of belief or something how yeah

50:23

do you get people how do you get people to consider that or become aware of that I guess what is the what is the

50:28

foundation yeah I guess like for um for the climate changing example that we brought up earlier right you've got

50:34

human flourishing on the longterm human flourishing on the shortterm different types of human flourishing how do you

50:39

get somebody because sometimes people could have a clash of a foundational belief and they can synthesize all day but they're never going to agree on a

50:46

particular thing yeah yeah that's kind of the deepest question actually is like where is the because then how does it

50:53

not all just like become relative like we're just like and and I guess I can say you know like some perspectives are

51:01

inherently unintegration never and abortion always

51:07

do not play well with anything else so that is just an inherently

51:14

unintegrated that I cannot include you in this process so that's you know and

51:20

then you know there are other perspectives that we can just say and how can you say that are just morally unwelcome you know like meaningful

51:27

synthesis on race is not between anti-racism and racism right it's between let's say like

51:34

the anti-racism of Iber X kendi and the color blindness of Coleman Hugh

51:39

something like that right so we can like and where do you how do you H how do you

51:44

know that you're not how do you know which ones to I mean we have to be

51:49

Discerning about which perspectives we integrate and how we frame the sides of the debate and like the how do we know

51:56

question how do we know that we're not weaponizing synthesis in order to convince ourselves of something we want to believe or that we're not just like

52:02

completely going off the rails and including whatever I don't remember what you just slavery you know I I I mean

52:07

there there's no foolproof way is the answer it's like maintain epistemic

52:13

humility you know like keep in mind that like the map no matter how detailed is not the territory so like whatever you

52:21

need to do whatever like contemplative practice keeps you tethered to the like

52:27

Infinity of reality that you will never fully understand like keep doing that whatever that is meditation prayer you

52:34

know in I I was raised Jewish in Judaism we have we have Shabbat and I think part

52:40

of the idea is that you spend six days a week like focused on the map you know and like one day a week just like

52:45

marveling at the infinity you will never understand so like whatever keeps you humble in that way I I like keep keep

52:53

doing that okay all right interesting it's funny that you brought up a there's the two topics that I don't debate on stream I just don't enjoy

53:00

doing anymore are abortion and veganism because I feel like both of them are um

53:05

they're the foundationally they're rooted in things that I would say are like outside of any fact determinative

53:12

humanly knowable thing because for abortion um people argue about it a lot of different ways but I think like

53:18

foundationally abortion is asking the question of like when do you become a human life worth why do you need to know

53:24

the answer aren't you still like choosing between like two like you could just say like which is the least bad

53:30

option because I think depending upon because I think you start to hit binaries um depending upon where you're

53:35

rooted at outside of what I can like factually argue so for instance but why do you need to know the answer to that

53:41

question because if you believe for instance that a a life begins at the very moment of conception there's

53:48

basically nothing save like the life of the mother is in danger there's basically because any other argument

53:54

puts you into horrible territory you're saying like sometimes you can kill babies the trol it's like you're just choosing the least bad option yeah but

54:02

it would be it would be like the trolley problem where on one side there's a person on the train tracks and on the other side you have to like spend five

54:08

minutes like doing a piece of homework it's it's so B because like in what because the because the translation is

54:15

like in what circumstances is it okay to kill a six-month old baby and this the answer is like basically never right I a

54:23

six-month-old baby yeah is a different is a different proposition yeah but but I feel like if you truly

54:29

believe that at the moment of conception as a human baby endowed with all the same rights as like an ordinary baby

54:34

yeah no I I I I think I think um I totally understand what you're saying I

54:40

guess I the way I think about it is that you can absolutely concede that that um

54:47

a fetus is is a human being at its earliest stages of development and it is

54:53

in a process of development it is a process so over time the moral calculus

54:59

of abortion changes over the course of a pregnancy and there's and there is a difference between where you are in that

55:06

process including whether you're right whether your VI and viability is a moving Target So that's its own but like

55:13

you have to acknowledge that something it's not like a switch has turned on and now it's just on I feel like most people

55:19

view I think I would actually view it I as a switch is turned on I think so because I think that if I look towards

55:24

the end of life I don't think I'm ever like graduating or degrad Dua like as

55:29

this person gets older they're becoming less morally valuable like it feels like it's a it's a a threshold question but I

55:36

guess what I'm saying is I don't think you need to know the answer to that question in order to ask yourself what

55:42

is the least bad option in this circumstance because you're just choosing between two shitty options kind

55:48

of or or or you're choosing between like what is just the path of least suffering

55:53

and I and I and I and I think that that I think that like a majority the largest

55:59

ideological diversity of people let's say could get on board with like under some circumstances abortion is the path

56:05

of Le is the least bad option yeah I agree that you don't even have to answer the the life at conception question I

56:12

think in a policy level I think that that works because you're basically aggregating a bunch of beliefs into like a thing that most people are kind of

56:17

okay with um but in terms of like the philosophical argument where you don't necessarily need to have the same level

56:23

of consensus as you would for like a legal argument we all have to kind of agree yeah yeah yeah yeah you're right

56:28

to and and then but then but then great but then we can like do the policy thing there and then in the philosophical

56:34

domain we can just let that still be like super complicated yeah possibly yeah but I I mean I would say that um

56:40

one of the leaders yeah one of the Leo's arguments in the in the um in that ruling for dobs was that despite Casey

56:47

and row uh and it was true uh we really haven't come I don't think we haven't

56:52

come much closer to a consensus opinion on abortion like it feels like gay marriage was the Supreme Court thing and

56:58

in 15 years you're like yeah we have gay marriage it's fine everybody's like more or less like okay with it but abortion is still like a yeah I mean Ruth Vader

57:05

Ginsburg had misgivings about row because she didn't think it should be the Supreme Court's decision and I

57:11

actually do think that row like really polarized us it like it like moved us further into our Corners such that I I

57:20

think enacting it like de democratically is actually much more resilient Pol

57:26

ially and culturally because because it like it it actually polarized us further

57:32

and and then both sides got like more extreme like one side is like shouting their abortion and the other side is

57:37

like you know saying like under no circumstances like abortion is you know it just it got us it it it pushed us

57:44

into our Corners yeah I I think I I kind of agree yeah I would I fight sometimes

57:49

against the doing things democratically is better because it creates consensus cuz I feel like it's a bit begging the question because it's like well

57:55

obviously if we can do where there's already some consens there and the people who are historically \[ \_\_ \] are like still continue to be

## Balancing Convictions and Adaptability

58:02

\[ \_\_ \] going to take longer it's going to take longer but I do think um yeah and then of course that begs the

58:08

question like are all states letting it be enacted democratically which is its own

58:13

but in ideal circumstances it is a more it is more resilient it is a more

58:19

resilient strategy um yeah but anyway abortion and veganism we don't do you

58:24

feel the okay you don't do each it's funny I people have asked me to do fa I don't know if I would call it faces of

58:29

meat haha I don't think I would call it faces of meat I don't know what I would call it but um why it's it's a similar

58:36

yeah because it's like what is moral consideration when does something Grant moral consideration when yeah I I I I

58:42

feel the same way about that one I feel like you kind of zoom out and look at the the you compare option like maybe

58:49

that's a more pragmatic approach and that it's like I don't need I don't I

58:55

don't we don't need to agree on whether Life Begins or whether what you were going to say I I I I think I I think I

59:02

agree with you maybe we're just I'm thinking of different types of arguments like I'll have an abortion legal or

59:07

policy debate and I I think I I don't think I've ever had one but I would have like a veganism uh policy debate but the

59:13

philosophical debate um on that level is just like it's way way way harder which

59:19

I think is actually good like I think is it's great how kind of complex it is

59:24

when you drill down into it like it's a good I it's like a good it's a good thing to reckon with it's like the Avail

59:30

meat is so available right in our like food system so Reckoning with the actual

59:38

like the philosophical complexity of that one I think is probably on like on some level good for us yeah to some

59:44

extent I do agree with that yeah I'm not a vegan at all but I um I I I was actually I was for a period of time and

59:51

um I mean you were an activist helping people living in trees you must have in California

59:56

exactly so I went through that phase and it's funny I I it what what what the

1:00:01

realization that I had was that the difference I was interested in was not the difference between a plant and an

1:00:08

animal it was the difference between a certain kind of production system or

1:00:13

another kind of you know it's like we can we can we can raise and kill animals

1:00:18

humanely and we can treat plants like \[ \_\_ \] you know there so it's so that that

1:00:24

was not the difference that I was actually interested like I realized per the that the impact I wanted to have on

1:00:31

the world was not the impact it was like I I had that Reckoning right with The Gap and that and so and I remember the

1:00:37

first time I ate meat after being a vegan for years I was at a wedding and

1:00:42

they served Lobster and lobster is not it's not a kind of meat you can just kind of like you have to get into the

1:00:48

anatomy of that animal in order to eat it like there's no escaping it and I was

1:00:53

I was actually just kind of like in at it cuz it's like it's there's I don't I don't know it's like it's got this whole

1:01:00

complicated anatomy and you have to like open things up to find the meat and I was sitting with someone who she was

1:01:06

like she was like did you know that they have to like you know they boil them alive you know and like what they do and

1:01:12

I had just been a vegan so I was like I kind of know I like well yeah it's like in order to kill something it has to be

1:01:17

alive before you kill it that's kind of the definition of killing whatever I was just like I'm not even going to go into this with you but she was kind of like

1:01:23

talking to me about like all this stuff about that you know and there I was was actually like marveling at the lobster

1:01:28

and I was just like who is loving the lobster more right now you or me I was like I am loving this thing yeah anyway

1:01:36

okay so so um yeah but um that for that one perverse incentives is a major kind

1:01:44

of um Factor because highly incentivized that drives our whole kind of like you

1:01:51

know foods like agricultural subsidies etc etc etc yeah so okay the only thing

1:01:57

for the vegans that um the veganism argument stuff that kind of irritates me is it's similar a lot to the vaccine

1:02:02

stuff where if I seen antia it's like if you live your whole life in some crazy Natural like fine I get it um every time

1:02:09

the thing that irritates me the most uh which is funny cuz I'm a I'm a meat eater but like when I see other meate

1:02:14

eating people who get so mad at like animal abuse incidences or whatever

1:02:20

where like a lion will get killed or a gorilla will get killed or somebody's dog will get abused or whatever and'll be like I kind of get an emotional level

1:02:26

but you must understand how morally bankrupt you're yeah have you ever seen a factory farm yeah I'm like come on

1:02:31

dude uh and yeah so there'll be a dog or a cat that gets abuse and I'll I'll tweet out something like oh this is the

1:02:37

worst thing I've ever seen like while eating my cheeseburger and chicken and everybody all the meat people get so mad like it's not even close to the same

1:02:43

thing man and it's like yeah um it's funny you put those together too though because that's a that's a that's a like

1:02:49

a uh thing that is kind of set it's people who are anti-abortion but eat me

1:02:55

it's like are you you how how far do you extend this idea of being you know like

1:03:01

appreciating the sanctity of life sure do you have a zygote a single cell just created and that thing is endowed with

1:03:07

all the protections of a human but then like a cow or a pig that's yeah yeah um freedom of speech okay freedom of speech

1:03:14

so we'll do yeah we'll do freedom of speech sure um the the debate project um

1:03:20

is um so you know the idea is that you

1:03:26

know in order to have a thriving democracy we need a thriving debate of ideas and yet here we are um and um and

1:03:34

therefore here we are what do you mean and yeah here we are and therefore here we are look at the look at the okay conversations everything that you you're

1:03:40

struggling with online so but in a traditional debate um only one

1:03:46

perspective can win right which in which can sometimes incentivize straw Manning

1:03:51

right it behooves me to make your position sound weaker so that my position can sound stronger I right now the placeholder name for

1:03:58

this project you're going to have to forgive me is antidebate I'm totally not antidebate at all I'm just and

1:04:03

it's the name is going to change but that's just the name I'm going to use for now so the idea with an antidebate

1:04:08

which placeholder name is that the person who wins is the person who best integrates the other person's

1:04:15

perspective into their own position which would then incentivize steel Manning right CU I'm have to really be

1:04:21

listening to you in good faith in order like matter and antimatter not like antimatter isn't like I hate matter or

1:04:26

whatever it says but I am probably still going to change the name anyway to like

1:04:31

dialectic debate or mhm integrate debate I don't know what it's going to be create debate um but um but I'm

1:04:38

designing the format now and I can tell you a little bit about um where it's at

1:04:44

but I will need to test it out okay so when I get there yeah would you be

1:04:51

down to would you want to moderate one or would you want to participate in

1:04:56

um honestly I enjoy both um okay yeah I enjoy either one so whatever you need I

1:05:02

guess I think it will be so cool to watch and that's the that's the thing

1:05:08

it's like how do you deal with these people who who like don't it's like you lose points well first of all do you

1:05:14

agree to the terms if not you don't get to participate and if you do and you're doing all these you know you're you know

1:05:22

engaging in bad faith you're you're just going to lose mhm yeah because at the end of the day like

1:05:28

wouldn't it be amazing to walk away from a debate with a better understanding all of us of the issue being debated about

1:05:36

that would be great so let's go for that okay yeah yeah gotcha um yeah uh okay um

1:05:47

oh wait I didn't know if you wanted to to to talk through any of that now but yeah if you want to do that I mean it's

1:05:52

we could yeah I mean I I don't have I have so um you know it'll start with some

1:05:59

kind of Covenant it's like what are the people agreeing to and then I mean I

## The Role of Moderation and Structure in Debates

1:06:05

don't have it's I I can kind of like summarize so um you know you have the

1:06:10

first person does their opening statement then the second person has to steal man the first person's opening

1:06:16

statement to their satisfaction right and go back and forth and if you find a word that's kind of being weaponized

1:06:22

like you said like either you agree to the definition or if you can't you just agree to stop using that word for the

1:06:28

rest of the the antidebate and then really yeah that um somebody emailed me

1:06:35

um I'm like a so I I know some philosophy terms and I've like looked

1:06:41

into a few things a little bit U but in terms of like reading full like philosophical texts absolutely not so I

1:06:46

I know I know like enough vocabulary to just abuse the hell out of it and have anybody that knows what they're talking

1:06:52

about you know hate me for it so just as a 41 um and a lot of things I just like very

1:06:58

briefly pick up because uh people email me Concepts or ideas or whatever um prefacing all of this so that if I

1:07:03

misquote something I something completely wrong feel free to correct me um but I had um a fan who uh emailed me

1:07:09

um a blur of um victon Stein vict vict Stein um and it it I don't know if he

1:07:16

actually believes or said this but it radically changed a lot of my approach to philosophy and debate and and

1:07:22

politics in general which was the idea that I think he said that I don't know in the first half for the later half of um vict victon Stein's life that he

1:07:29

basically believed that all problems of philosophy were illusory and it's really all just matters of language

1:07:36

misunderstanding and that if a philosophical question seemed very complicated or very in uh like deep or

1:07:43

difficult to solve what's probably happening is there's a language problem and once the language problem and the

1:07:48

syntax is figured out um the semantic understanding follows like very naturally and there's a lot of um

1:07:53

there's a lot of debates or conversations now where I'm like okay hold on um we're having this is a big

1:07:59

semantics thing right now which I hate that that has such a negative connotation because semantics are arguably the most important thing CU

1:08:05

language is like one of the most maybe the most important thing we have as humans yeah um but I find for a lot of

1:08:10

people that sometimes the debate is a matter of like can we semantically be on the same page um or syntactically be on

1:08:17

the same page where we're using like the correct not not correct that was a really bad word that would have triggered somebody yeah yeah we're using

1:08:23

a shared definition we're saying and once you start iron out a lot of the differences of how we're using the words

1:08:29

the um the the um I was going to say discongruence uh the uh some to just add

1:08:36

no no it doesn't work um the the in congruence of the positions will slowly disappear as you kind of like bring your

1:08:42

language into alignment so something that seems as kind of like trit or um

1:08:47

trivial as like okay well let's just make sure we're using the same words that a lot of the times when you're arguing with people yeah just getting on

1:08:53

the same page of that the abortion one I think is a good example

1:08:59

ISU aomy womu AB is bad and it's like okay we

1:09:05

need to talk about like the is a fetus a human because that's really the only thing that matters here and if you guys could just kind of like move in that

1:09:11

direction by collapsing your language understanding what you're saying like you'd be having a more sub substantive conversation I guess yeah yeah um have

1:09:20

and you've done that and it's helped you sometimes it does yeah but but or at the

1:09:26

very least if it doesn't resolve it at least it gets us to a more meaningful conversation so somebody will say

1:09:32

something like like Trump weaponize the doj or Biden weaponized the doj I'm like okay hold on I'm so my gut is to fight

1:09:39

on this is I think in one of these is very true one of is not true but then it's more like hold on because because I

1:09:44

could have a two-hour debate on that and at the end be like wait a second when you say weaponize the doj what do you mean by that and they like oh well they

1:09:50

press charges against like a political opponent like okay hold on do you think that that's weaponizing and then I realiz like \[ \_\_ \] why did we just have

1:09:56

this whole conversation what do you weapon yeah and that that' be an example of like let's actually what do we mean when we even say this and then if you

1:10:01

resolve that they're like oh okay well if that's the case then I agree with all that or I disagree with all that like we didn't need to waste our time talk you

1:10:07

about that yeah so a question so we we we were time a little bit before we started like do you think that someone

1:10:14

like Ben Shapiro would agree to participate in something like a renamed

1:10:20

antidebate why or why not um

1:10:26

H we've um my mind immediately left the orbit of anything having to do with this

1:10:31

and it's now a whole bunch of macro layers on top of it that have nothing to do let's go through the macro layers

1:10:37

yeah yeah yeah yeah I'm just explaining my thought those might be the perverse incentives yeah partially so I think the

1:10:43

answer would be um given that there's like an appropriate like um publicity that he's obviously you know let's say

1:10:50

it was hosted on Lex fredman or somewhere like the answer would be absolutely yes he would I think so yeah

1:10:56

but for the worst reasons um one of the things that I am very frustrated in

1:11:02

right now when it comes to political discourse is that people have there's an aesthetic of a thing and people have

1:11:08

abandoned the function of the thing because but the aesthetic is so sexy and favorable it's like nuon signaling or

1:11:14

whatever something like that yeah I have to like I tell my audiences and I and I tell people this that like when you come

1:11:19

to my stream and I describe myself like every single thing I say should be a massive red flag to you because if I

1:11:25

ever hear people say anything like oh like for me personally I do my own research um I you know I think that you

1:11:30

should have a considered position between like multiple points of view um I think that um uh like I I I don't

1:11:38

belong cleanly to any political party like all of these things are when I hear somebody say this like you're absolutely

1:11:43

\[ \_\_ \] full of \[ \_\_ \] you're hard if somebody says like for instance like oh I'm like I'm nonpartisan you're conservative you just don't want to

1:11:49

admit it every single time every single time or somebody's like I do my own research okay that means that you've listened to Joe Rogan opinion on it and

1:11:56

one other podcast you've never read a paper you've never read anything in your entire life um yeah so like a lot of

1:12:01

things I say are like red flags and it bothers me because the aesthetic of these things has become so attractive

1:12:06

yeah so when I think of would would somebody like Ben Shapiro do a show like that I think so because I think it gives

1:12:12

the aesthetic of oh well look I'm so carefully considered on my positions that I would even do like a philosophy

1:12:17

exercise on this particular thing show how considered I am on these yeah um I think it would be interesting to hear

1:12:24

him do a thing like that but the topic is like um drugs for Trans drugs for 14y

1:12:31

olds that would be really interesting can you actually steal man the argument on that or some some position where it's

1:12:37

like I want to hear you say a single positive thing about this even if you don't agree at the end maybe the synthesis is you know 18 and older is

1:12:43

only the yeah yeah yeah yeah yeah yeah and that's that is one way that it could end is that we've just clarified the

1:12:50

disagreement possibly yeah but at least which which is also helpful cuz I've noticed also when comes to um uh people

1:12:57

engage almost intuitively in a way with the concept of synthesis and that they

1:13:03

will be a thesis of a thing they believe in an antithesis and then they'll AR um they will um not artificially um there's

1:13:10

a word I'm looking for not aesthetically they they'll go through that superficially superficially yes performatively superficially they'll go

1:13:16

through that process but not really and the way that I identify this is sometimes people will when they're doing

1:13:22

the thesis um I don't use the word thesis antithesis because I don't read germanian everything no but like

1:13:29

somebody will um the the thesis part will be why is freedom of speech will say why is it so important freedom of

1:13:36

speech is really important because everybody in society needs a voice um you can't have one authoritarian body

1:13:41

dictating who's right or wrong we need to be considering different points of view um liberal Democratic Society only

1:13:47

works when we can have different points of view in society right and then the antithesis will be okay well what does the other side say um they want to be a

1:13:54

nanny police state yeah and a strong yeah they're doing strong maybe yeah or it's not even a strong man but it'll be

## Lessons From High-Profile Conversations

1:14:00

like I'll call it like the Outer Perimeter of like the weakest it'll be like when a person says yeah for I'm

1:14:06

attacking conservatives right now a lot usually I do both sides on to give an example but I don't want that buy right now I hate conservatives but like it'll

1:14:12

be for Donald Trump right I'll hear somebody like oh I don't support Trump on everything and it'll be like okay tell me what you don't support him on

1:14:17

and it'll always be like I think he can be mean sometimes on Twitter what do you support him on I think his position on

1:14:23

Ukraine is correct I like his domestic policy I like his approach to Tex station I think and it's like okay okay so the things you disagree on are irrelevant and the things you agree on

1:14:29

are all the core ideas you're like the disagreement are like the Outer Perimeter so that's like a thing sometimes that will happen with this

1:14:34

yeah is people the outer the antithesis will be the weakest most Outer Perimeter things that nobody cares about yeah yeah

1:14:42

well he'll um yeah he'll lose points for yeah he won't win that's good yeah yeah

1:14:49

so um yeah the it's it's it's yeah I guess it just goes back to the like

1:14:54

anything can be weaponized it's like but I guess um you know if we're at the

1:14:59

point where we're weaponizing synthesis like can I say that we're moving in the right

1:15:06

direction like if this becomes the thing that people are wanting to perform if they're doing you know if

1:15:12

they're performing Nuance even if they're not as Nuance as they claim that

1:15:17

they I mean if if Nuance has uh you know

1:15:23

cache I yeah I understand what you're saying I think I would actually disagree I think if people were doing it I think

1:15:30

then that would be good even if they were doing it poorly the the aesthetic as a substitution for the the function

1:15:37

of a thing I think is actually incredibly annoying and damaging and that I would actually prefer like I would much rather go into a room and

1:15:43

fight with 10 hardcore conservative or Nazis right that are super honest about

1:15:48

yeah rather than the hardest thing is when I have to fight with one super conservative and nine centrists who

1:15:55

because now my position is I look insane I'm so far to the left because not only the conserva all the centc disagree with

1:16:01

me and I'm like well \[ \_\_ \] I look crazy now as opposed to like if you nine conservatives then at the very least we would both be like occupying opposite

1:16:08

spaces but the um sometimes that that that aesthetic of considered difference in the middle makes certain positions

1:16:15

look way more extreme radical than I think they actually are yeah yeah I mean well maybe now going back to the beginning yeah I don't so I I don't I

1:16:22

don't consider myself a radical Centrist okay I used to call myself a promiscuous

1:16:27

pragmatic pluralist okay until I discovered integral are you familiar with integral Theory that's a whole

1:16:33

another inter from calc BC but I don't know what no so that so well anyway inter I was like ah one word instead of

1:16:40

three so much you're so much less of a mouthful but um yeah I don't for me it's it's like yeah sure I guess I'm a

1:16:46

Centrist on the issues that maybe I'm in the center on but it's just on those

1:16:52

it's like you're there it's still it's not to dimensional it's three-dimensional so you yeah so like

1:16:59

somewhere in your notes I think I read that you because you CH you changed your

1:17:06

views you that sometimes gets weaponized against you of the like um like I don't

1:17:13

I don't know exactly what people would say they'll call you a flip flop or something right and so but that's assuming that it's a two-dimensional

1:17:20

Spectrum right that's assuming that you've just gone 180 degrees in the opposite direction but doing B baby bath

1:17:26

water is a vertical Direction yeah and that's so I think that's how you can kind of diffuse the you know like the

1:17:32

kinds of change I was interested with reckonings the podcast weren't changes from right to left or left to right it

1:17:38

was from it was from certainty to uncertainty right it was from Dogma to

1:17:43

ideological Liberty it was from being fearfully attached to my views to having

1:17:49

the freedom to reflect on them and be critical of them and change them in order to adapt to the reality around me

1:17:56

so once you include that I think that can help diffuse this like weaponization of flip-flopping or

1:18:03

whatever is to is to like is to be able to point to like no actually I kept the baby and not only did I keep the baby

1:18:10

lose the bath water and end up with a bigger picture but I now hold my views in a different way I'm able to like hold

1:18:17

them tightly and Loosely by choice yeah like there are some that I still hold tightly you know my my husband is has a

1:18:25

very I would say like a tight relationship with his Jewish spirituality it's like the Ten

1:18:31

Commandments I didn't choose them that's not like I get to just like pick it's like they were given to me I am

1:18:37

commanded to do these things but I and I appreciate the especially in an era of

1:18:42

like getting to choose your everything like there are some things I'm just not going to choose there are some things I'm just going to hold lightly as

1:18:48

although that that is like kind of a choice but it's a choice I'm almost like giving away to have and then there are some things I'm going to hold loosely

1:18:55

and that I think you can like point back to the people who are weaponizing your change against you yeah and acknowledge

1:19:01

that there's yeah a bigger capacity that you've inhabited hopefully yeah yeah for sure there's um I guess three things on

1:19:08

this uh the first thing is yeah when you when you mentioned the getting people who to make these like big vertical changes I guess and how that's like a

1:19:14

negative thing um it always is like it raises my eyebrows when somebody's like yeah um when I was younger I was so dumb

1:19:20

I used to be like a hardcore uh you know like communist socialist and I realized ized how dumb that was so that's why now

1:19:26

I'm a hardcore Anarchist libertarian or whatever and it's like okay that's cool interesting you swap that one extremist

1:19:32

anti whatever belief or another but okay yeah um it'll take like one more 180

1:19:37

degrees until until you'll get there eventually yeah um one thing that I uh

1:19:42

one thing that I also noticed too and it's very funny because I'll watch this happen in live conversations is um

1:19:48

something that I've said before this is so hard to do in content creation spaces and I think it's probably hard to do for

1:19:54

humans in general but um there there's like there's levels of maturity that

1:19:59

hopefully every human moves through where um when it comes to dealing with feedback as a public figure it's very

1:20:06

difficult because there's a whole bunch of stuff out there and the obviously the

1:20:11

the human the the base like level zero is like I'm ignoring all of it screw these people okay um and then the next

1:20:17

level is like kind of taking way too much feedback to Heart where you're like

1:20:22

oh my God like everybody hates me on this thing and I don't think I was that bad or whatever um and then ideally

1:20:27

there's this version where you look at things that people are saying and you understand that even though it might not

1:20:34

be correct it there's something happening there that's like worth paying attention to and it's very hard

1:20:41

sometimes to get people to understand that um like I don't I don't believe like people can be um irrational I think

1:20:46

sometimes and people are never random just because somebody's being irrational doesn't mean that their behavior is they're flipping a corner and everything there's a reason why they're doing a

1:20:53

particular thing oftentimes it's really predictable

1:20:59

people NE this is like a a proxy for um and the

1:21:06

uh oh and it's funny because I remember I was having a debate one time with a guy and it had to do with um not to open

1:21:12

the whole housing thing um I'm a very wealthy person I rent okay I don't want to buy a house I just don't need to and

1:21:18

the idea that like buying a house is just clearly super in every single way to renting is just stupid it's become a political belief but financially that's

1:21:24

not the case that buying a house is always the best financial decision um and there are pros and cons to buying and there are pros and cons to renting

1:21:31

and um just because of morally how people feel about the economy or capitalism or landlords or whatever there are like very negative

1:21:37

connotations with landlords very positive connotations with with buying a home and I was arguing with a guy about this once in my stream and I was

1:21:43

bringing up and he's like why would you ever like whatever and I was one of the things I said was well the liability for an apartment is very nice because the

1:21:49

worst thing that can happen with an apartment is you get kicked out um the worst thing that happens with a house is your upsite down no mortgage you have a

1:21:56

huge liability you have to file bankruptcy and even my chat because my chat is a bit to the left of me on this issue everybody's like oh Destiny you're

1:22:02

out of touch you don't understand like this is like nobody this doesn't happen blah blah blah and I think probably 20 or 30 minutes into this debate with a

1:22:09

guy like I end up um because I've picked up a lot of new audience members over the last couple years so they don't know as much of my history but um my parents

1:22:15

for a variety reasons ended up quitting their work when I was like 12 or 13 and they had to file bankrupcy we got forclosed out of our home and that was a

1:22:21

whole ordeal oh wow and as soon as I said that this rather than the chat being like Oh okay maybe he has his

1:22:27

perspective or whatever it all changed to oh you're too emotionally bought into this or oh you're like to and I'm like okay yeah so sometimes people will get

1:22:34

all this to say that sometimes people will accuse you of having a particular bias but then the the that's a proxy for

1:22:42

I disagree with your opinion but I don't want to say that I'm going to find a reason to say that yeah and if you

1:22:48

change the reason they don't change their opinion they find a new reason to

1:22:54

hop to M opin which that's just very to me and

1:22:59

you can see that a lot of way somebody like disagrees with a thing and they're like oh it's because of that and then you find out it's the opposite it's like

1:23:04

well of course whatever it's because yeah yeah people also I find that they it's like they find it like almost

1:23:11

disappointing or something that sometimes it'll take personal experience to change your mind but it's like did it

1:23:18

really have to take like your daughter being gay or something to change your but but for me it's like got thank God

1:23:25

that through personal experience I mean imagine if we all had to like read C I mean we should read all kind but like

1:23:31

thank God that personal experience can change us because that's something that

1:23:36

we're having all of the time yeah you know so for me it's not that's not like a it's like please allow my life and the

1:23:44

experiences I have in my life to inform my understanding of reality thank you um

1:23:50

I'm curious about your um yeah your goals you were saying like your I guess

1:23:55

your your goals for your Channel or your goals for this show and what has been

1:24:02

challenging yeah oh you about that a little before um one other quick thing I was going to say about something you

1:24:07

said before is um uh I don't think that being right or wrong is the most important thing I think H matching your

1:24:13

convictions I think are really important too so um I would rather somebody has an appropriate level of convictions for

1:24:19

everything they believe rather than they're generally right or not wrong that often hearing somebody say like I

1:24:25

actually think that uh I think that this policy is is a good one but I don't really know that much about it so like you know whatever yeah that's actually

1:24:32

another question to add to your is like what is your percentage of certainty yeah that's a really good one because

1:24:38

then it's like oh actually like pretty low you know or I hadn't really thought

1:24:44

about that yeah which is good because if somebody yeah well but then yeah but then if it's an influencer content

1:24:49

creator then I'll yeah do you present it that way what is your percent I yeah I would totally ask that question it's

1:24:54

like first it's like what do what do you believe about this or what is your take on this and then what is your percentage

1:25:00

of certainty about that or not or not percentage uh presentation how do you do you present it this way like if I ask

1:25:06

somebody like like if I force somebody to consider that how confident are you and they're like oh maybe like 20% I'm like okay well so here's a clip of you

1:25:12

saying like doesn't sound like a 20% take yeah that's actually one of the

1:25:17

last things at the end of the anti debate is uh is like how based on your

1:25:22

experience today like how will you move how will you move forward in some kind

1:25:28

of like different way based on how how you're going to talk about this issue or how you're going to act on this issue

1:25:34

yeah yeah but um yeah what are your goals so originally my goal for Bridges

1:25:40

was to um I wanted to bring on people with substantively different views from

1:25:45

yours or from each others from mine from yours uhhuh and then we could kind of hash it out that sounds more violent

1:25:52

than I I mean that's like what the antidebate is designed to help you do yeah

1:25:58

yeah and I think one of the unfortunate discoveries that I made um so like I um

## Media, Polarization, and the Path Forward

1:26:05

for most people famili with my background I I'm very hardcore or most people in my audience I sorry are familiar with my background you know I

1:26:10

was a very hardcore debater roll around in the mud 2016 to 2019 and I was like okay well let's like tone it down a

1:26:16

little bit be a little bit more empathetic and you know different environments call for different rhetorical Styles and they get different

1:26:21

types of fans and they're good whatever but um one of the things that I and it's always this balance of like um broadly

1:26:28

speaking we call it responsible platforming or whatever but it's always this balance of like I want to talk to you and I want to challenge your views

1:26:34

but I need to do it in a way that you're open to it so it's probably can't be me screaming you the whole time and I wanted to be somewhat productive and I'm

1:26:40

open to being wrong on things as possible and I think probably at the largest reach I've had I think was

1:26:47

probably towards the beginning of this year um where I spoke to a lot of DA wire people basically it was I think it

1:26:52

was like Ben Shapiro was Jordan Peterson it was Candace Owens it was Michael nuls and I had come

1:26:57

away I guess happy initially cuz I'm like okay well I'm having more of these conversations I wish we could have kind of you know dove into some more things

1:27:04

here whatever and then at the midpoint of this year the um the first the Trump assassination attempt or whatever

1:27:10

happened and then I saw all of the discourse unfolding on this and I think I was just like this is I'm I hate my

1:27:15

life right now because um the uh without diving too much into that thing or we can dive I don't care um I noticed that

1:27:23

it was the first time that like clearly observed that conservatives control the entire media landscape because this idea

1:27:28

that liberals had to like kneel and beg for forgiveness that like this horrible thing happened and I'm like okay hold on wait a second you guys have been engaged

1:27:34

in the insane \[ \_\_ \] rhetoric for like four years why the \[ \_\_ \] is this our fault are you serious and um I and I'd

1:27:40

made some I'll say pretty extreme statements uh to that effect absolutely had um and I had and I had made Extreme

1:27:46

statements and I stand by all those statements and I'll continue to do so people ask me about him but um I noticed it after that happened now

1:27:54

cons is like oh no like Destiny is uh he's like unhinged like there's no way that I can talk to this person oh okay

1:27:59

and as I go back and I analyze the conversations we had before and I analyze like the conversations I want to have now I think actually the main thing

1:28:06

that changed because they have a lot of unhinged people in their programs I think that the thing that was happening before that was just not as perceptible

1:28:13

to me although was the thing I worried about was if I Believe in a Thing but I can bring on a guy who is completely

1:28:19

opposite to me but he promises to like neuter himself enough such that I can say that I have had the conversation at

1:28:25

least it validates my position a lot and I don't want to play that part ever and

1:28:31

it kills me that I had a conversation with Shapiro where I you know it was like a like with kids clubs the whole

1:28:37

time or with Candace Owens or there was no one moderating it was just an open conversation between you two well there

1:28:44

was a moderator for um for Ben Shiro but it was Lex fredman so it was like intentionally like a very light oh it

1:28:50

was on his show yeah um and that should have been a more brutal conversation cuz I just think a lot of what he said was

1:28:56

completely unac is not going to do that yeah yeah and um yeah and then same thing with like with Jordan Peterson

1:29:02

that one wasn't moderated and I provided a bit of push back but like it was a pretty gentle conversation all considering like the things that he'

1:29:08

said but then um yeah but then I noticed afterwards that that even after being so gentle that like sometimes you know like

1:29:15

Jordan Peterson after like oh I think Destiny a guy who wants to be right all the time or whatever and that was a very for my stand was a very gentle

1:29:21

conversation given how absolutely \[ \_\_ \] absurd uneducated a lot of things that this man who supposedly and purportedly an educated man is saying

1:29:28

yeah um yeah so so basically all that to say that now I'm like okay well it feels

1:29:34

like people want to have challenging conversations in so far as they can have the aesthetic of a challenging

1:29:39

conversation I brought on Destiny and he disagrees with me when we spoke but we didn't really hash out any of these yeah

1:29:46

um so then that I guess all to say that for the Bridget show or whatever so now I'm curious like I don't know if anybody

1:29:52

would come on it's like I want you to come on and I really want to dive into this issue cuz I think yeah that's frustrating to me well I mean hopefully

1:29:59

I mean I think yeah I think the antidebate is like precisely designed to

1:30:05

help with this because it gives you a structure then we don't have to like worry about like do we have to use kid gloves or are we getting into it or are

1:30:11

we not getting into it it's like someone you you know exactly the format and you

1:30:17

agree to it in advance and then someone is going to moderate it and it probably

1:30:22

if it's obviously if it involves like any of these guys you shouldn't be moderating it you should be in an antidebate with them and but the but the

1:30:29

moderator is going to be a hard role to fill because it's got to be someone who yeah like can can like abide by this

1:30:35

structure and also who has some domain expertise so they can kind of like but I mean which is pretty standard I guess

1:30:41

for a debate anyway but yeah that is exactly what this kind of format would help alleviate because there should be

1:30:47

there should be like productive and fruitful dialogue between these different perspectives on the internet

1:30:54

be the case that like they're not talking at all and it should also not be the case that like when they talk they have kid gloves on and and they don't

1:31:00

really get into it or they just fight and nothing really super productive happens like we should all walk away

1:31:05

Having learned something and and hopefully learned like who who is actually better at doing this kind of

1:31:10

like synthesis integration thing and who is just not I mean you're you're like your your your like weak Steelman is not

1:31:18

going to get you very far in this context yeah one of the um one of the reasons why and there's is a whole other

1:31:24

conversation we had about like the media environment that we inhabit and how people relate to that and relate to the

1:31:29

real world but one of the nice things about uh democracy or freedom of speech or whatever is that this dialectic can

1:31:37

happen naturally without anybody actually doing it because your thesis

1:31:43

and your antithesis are just both sides fighting with each other and then the integration is just the tension between

1:31:49

the two and then the synthesis is whatever ends up like codified in law or wherever you're you know you end up

1:31:55

heading but if these two things become totally separated and then you cut the mhm Corpus whatever that middle part of

1:32:02

your brain is yeah you cut it off then it's like you have no more of that and it just like devolves totally it's like

1:32:07

schizophrenia or whatever would happen if you didn't have that um the the way that from what I understand um the way

1:32:16

that our Consciousness has Evol I mean there is there is like generally conceptually a thesis antithesis

1:32:23

synthesis and then the synthesis becomes the new thesis and you keep on but um but the biggest leap that

1:32:31

um that I think we're um we are ready for is this leap from because because is

1:32:39

the leap from my way is right all the other ways are wrong to this like under

1:32:44

what circumstances is Which Way helpful even though I like some some ways are more fair or beautiful or just than

1:32:50

others that is cuz even with even with the into thisis there has been a it's

1:32:56

like every time we make some kind of like civilizational or we go from monarchy to democr whatever we we we we

1:33:03

do the like previous way bad current way right mhm and that that is that will be

1:33:09

that that is kind of like the next leap that we are due for is the wait a

1:33:15

second wow like look at how many ways we've given birth to look at this Cornucopia of ways of thinking and being

1:33:22

and doing all different kinds of things and thank God we've given birth to so many ways and some of them we can just

1:33:28

leave off the table forever like slavery but for the most part like most of them are useful in some circumstances so we

1:33:35

can kind of like we can we can like cease doing the previous way wrong current way right thing and and like

1:33:42

just appreciate the Cornucopia yeah the shades of great thing is very hard or the pros and cons thing is very almost

1:33:47

inhuman it requires an almost inhuman amount of um consideration I guess there's a there's an interesting

1:33:54

essay by the Isaac azimov guy science fiction writer um who he has an essay

1:34:01

over like Flat Earth basically um and it's this concept that a person that

1:34:06

believes in Flat Earth has actually made a fairly intelligent generalization in

1:34:11

that the entire Earth like the surface must be on the aggregate um uniform um which is which

1:34:18

is smart it means you don't believe that it like there's just random holes and heill that yeah that makes sense the aggate right and that there's a very

1:34:25

very very very very slight curvature I don't know what the degrees is of the earth to like make it a sphere there a

1:34:31

very small change from Flat Earth to spher uh spherical Earth um but that Flat Earth is a good generalization from

1:34:38

believing in Randomness that a spherical Earth is a good generalization from a flat Earth and that your actual sphere

1:34:45

it's like an oblet sphere or or something because you bulge in the center because of um angular momentum or

1:34:51

something um that that's like the best one but that it's not fair sometimes to

1:34:56

say that you know a flat arther nowadays it is but like back then yeah to say

1:35:01

like oh Flat Earth isn't entirely wrong andic Earth is not entirely wrong and that all of these like incremental improvements are important to realize

1:35:08

totally yeah and that's why yeah that's why I don't usually speak in ter or I try not in terms of changing mind but

1:35:15

expanding mind because you can take their partial truth and and give them a bigger picture that still includes their

1:35:23

perception that when I look around the earth looks flat similarly I mean you get and I think to the extent that you

1:35:28

do that that will like something like qanon it's like yeah there is a global

1:35:33

Elite with too much power it's not a satanic cabal of shape-shifting lizards

1:35:38

but like you do have a partial truth there that is really worth including yeah something that's very

1:35:45

difficult um and I don't know if you would get this intuitively from a stats background but there's like there are so many things in terms of numbers and like

1:35:52

doing like correlation and R ands it's like um it's you sound like a like I

1:35:59

sound insane as soon as I start talking about this to um to like a to a conservative but like just because something is factually correct like you

## Tools for Epistemic Humility and Better Understanding

1:36:06

have a factually correct statement that has sometimes no bearing on whether or not your conclusion is factually correct

1:36:13

or not that is very hard sometimes to make people understand that the idea of drawing a conclusion from a set of facts

1:36:20

is a whole skill in and of itself and that just presenting a couple facts doesn't really mean your conclusion is

1:36:27

valid or not that there's like a whole process there of integrating information and and creating something that's like

1:36:33

you know like a true conclusion and yeah sometimes it's very difficult to to argue with people who have like one or

1:36:39

two facts and it's like well just because that's the case doesn't necessarily mean yeah the conclusion

1:36:45

holds and sometimes there's a yeah sometimes there's even simple questions like you can ask somebody um like the

1:36:51

debt the US debt is a big one where and it's surprising too because even the last conversation I had was a guy who's

1:36:56

a big business guy I don't know if you ever heard of quest cookies or the okay protein stuff but um he made this whole

1:37:02

business tremendous business really smart guy and but he's like fully bought into as a lot of the Silicon Valley

1:37:07

types now are I don't know they like don't need to eat food or something oh no no no it's not that it was the whole like libertarian like gold standard like

1:37:15

abolish the Federal Reserve all this type of stuff and the US debt is like the most evil thing in the world and I remember I asked him a question I was

1:37:20

like what do you think the US debt should be ideally and he stopped to think about it and he never considered

1:37:25

it before and then he was like I guess ideally would be zero and that was a very interesting answer to me and I

1:37:31

pushed him was like cuz you're a business guy and if you had a business that was like growing and expanding and you saw that they had absolutely no debt

1:37:38

you would say what are you doing what leverage what you can borrow money cheaply expand your business you're going to make more than the interest on

1:37:44

this obviously like a business with no debt is is either failing or something is broken or not right there so it was

1:37:50

interesting that he gave that and it's was like okay well now if you say that the debt is um if you say that the debt is good and

1:37:55

he like yeah on our business there are certain types of loans account like okay and and but then he says but the loans like we never went crazy into debt or

1:38:02

whatever and I'm like okay but like when you took out loans it was probably like being in debt or not is probably like a

1:38:09

percentage of your revenue or your assets right so it got you took out more and more and more debt but it was always

1:38:14

like right and I was like it was interesting that we think of the US debt we always think of it in in an absolute

1:38:20

number yeah but we I don't even know if we know what the countryes assets are and we don't usually compare to GDP but

1:38:26

like if I was to give you an ordinary person's balance sheet like if I were to tell you right now I can tell you a guy who is $10 million in debt ironically

1:38:32

you'd probably think the person is Rich or poor if they were like $10 million in debt yeah yeah exactly but $10 million

1:38:40

Jesus you yeah how do you have $10 million of liability yeah exactly but that's like very but if I tell you like for the United States you know we have a

1:38:47

debt of like 20 trillion or whatever it's like oh my God this is the worst thing in the world but that's like an example of um yeah of a thing where it's

1:38:52

like yeah people have very strong things like opinions on things they'll have like a factor two and it's like what does this mean another one is like the

1:38:59

illegal immigration all like there's so many things that get repeated I remember arguing with this guy and he was like

1:39:04

there's 40,000 illegal immigrants in this country right now with like violent criminal felony records and I was like

1:39:09

okay hold on and he's like I'm like there are 40,000 illegal immigrants he's like yeah and it's like you said they're open borders they just going like yeah

1:39:16

um nobody's checking these people he's like yeah how do you know they have criminal records and he's like what do you mean

1:39:21

I'm like well you said there 40,000 people right that nobody's checked yeah and there was no answer for that

1:39:26

question I can tell never considered in his entire life um yeah yeah I like the

1:39:32

what's the best case scenario question that's another good one to have in your back pocket is like what would be your ideal scenario because that can also get

1:39:39

us out of the level of like whatever what you know and um you know just like

1:39:45

the locked positions and into the into the into the goal out of the strategy into the goal productive yeah well the

1:39:53

well the goal is is something that that a is like the most important question because that determines what the

1:39:59

strategy should be right is the goal and the goal is also probably something that we agree on more than we might realize

1:40:06

and if the question becomes then what's the best strategy for achieving the goal that's a completely different question than like your strategy versus mine just

1:40:13

like absent any conversation about what the actual goal is yeah so one very very

1:40:19

very frustrating thing to me is um so I I used to do um like I've read a bit

1:40:24

about ethics and then at some point I was like okay meta ethics is stupid no more meta anything um and then you know

1:40:30

I like okay normative ethics and then I was like you know what normative stupid whatever one one of the things that I

1:40:35

feel like um that there's a whole list of I also don't take anything I say about this but like one of the frustrating things is like people will

1:40:40

give me like there'll be so many challenges like deontologically where it's like you the classic one is like the Nazis is knocking at the door

1:40:46

there's a Jew in the basement do you lie or whatever and and I've seen like all these esoteric normative applications of

1:40:52

where it's like what about threshold ology like you're a day ontologist up to a certain point or whatever it's like okay well that kind of sounds like

1:40:57

consequential or utilitarianism essentially and then on the utilitarian side you know people will say things like okay well you're going to kill one

1:41:03

person to say five and I'm like yeah that's a good utilitarian rule I guess and like okay well now you have a society where nobody goes to the

1:41:08

hospital because as soon as you go in they're going to execute you to take your organs to heal everybody like okay \[ \_\_ \] you're right well what about and

1:41:13

then they're like well there's this thing called Rule utilitarianism you craft a rule and it's like okay well this is starting to sound like deontology youve got like a universal

1:41:20

principle or whatever so \[ \_\_ \] normative ethics all this say that um one of the

1:41:25

things that uh and it's funny cuz I used to make fun of uh virtue ethics or like intuition when it comes to moral stuff

1:41:30

and I'm like I feel like actually morally I think intuitively we're we we're like 98% aligned totally which is

1:41:36

which is part of why I said like there's no foolproof way it's like you just kind of have to maintain your epistemic

1:41:41

humility and keep some kind of contemplative practice that sure keeps your intuition healthy because the

1:41:47

second you attack the second you decide the map is the territory then you're going to get yourself into real trouble

1:41:52

yeah yeah but it's frustrating to see how different we feel about things sometimes when it's like I'm pretty sure

1:41:58

like like uh like intuitively 98% of humans are like about on the same page

1:42:03

as everyone else yeah yeah totally that that and and and yeah and that's also are you familiar with the phenomenon of

1:42:10

the perception gap of the how we just are like seeing completely warped

1:42:16

visions of each other online it's like some of this data might be outdated but it's like Democrats think that only 30%

1:42:23

of Republicans support sensible gun control it's something like 70% sure

1:42:29

Democrats and Republicans think that like 50% of the other side thinks

1:42:34

violence is Justified and it's only like 5% it's like we're basically fighting with mirages so much of this is like

1:42:41

again back to the social I don't know if you watch the social dilemma the Netflix documentary okay so I used to I I used

1:42:48

to work with the center for Humane technology which is the organization at the heart of that film that it's all

1:42:53

about how social media is like hijacking human consciousness basically but um yeah there are we are not even seeing

1:43:00

ourselves clearly online we are in many cases fighting with it I use the metaphor of a fun house mirror it's like

1:43:07

we see the like Beauty filtered versions of our tribe and then the completely like warped versions of the other tribe

1:43:14

and so naturally we're up in arms and but like we don't even know how much we actually agree

1:43:19

mhm so that's why I joke that we're like a happy marriage waiting to happen we split the

1:43:25

polarities we uh we actually agree more than we realize so yeah I think a lot of

1:43:31

this would be cleaned up with yeah with a different information ecosystem which

1:43:37

gr is not it's not that's a a very tall order of course but I but I think I mean

1:43:42

it's like you have to we we apply pressure up and down the leverage it's

1:43:47

not just like we must change the law we also but I also think designing a new

1:43:53

format for debate is also helpful so I think you know it's like just like it

1:43:58

all it all kind of needs to change but you cannot you can focus on whatever domain is yours and I like the domain of

1:44:07

you know speaking publicly and engaging in debate and civil discourse I think is

1:44:13

an excellent place to be and push I think there's I feel like there's one big fundamental change that like if this

1:44:19

could happen it would be good um I mentioned the the ran stuff in high school or whatever and that this like

1:44:25

kind of led me to some epistemic humility cuz I'm like okay I need to not be so um uh in uh influenceable

1:44:32

suggestible or something I need to not be like so boted so easily to things um another thing just totally by chance is

1:44:37

I took um I took a really good site class in high school and I don't know if it was the teacher or if it was um the

1:44:43

book it was a book by zimbardo I think he the book he was actually my professor that's St so awesome okay oh you didn't

1:44:50

like him or no no I didn't know but it's just it's just insan I mean you know about the Stanford Prison Experiment and everything yeah I think people don't

1:44:56

like the outcome as much I don't care though I like zardo I think a cool guy I mean we learned a lot but yeah no he no

1:45:01

no no I no I feel very grateful to have had him as a professor but anyway yeah he seems like a cool guy I don't you're

1:45:06

about to destroy my impression but um yeah um but the um one of the best

1:45:12

takeaways that I had from that class oh my God it was so important was how little I should trust my own mind to

1:45:19

intuitively or organically arrive at correct like empirical determinations that like um there are so many things in

1:45:26

so many different ways you remember with such bias and I realized like I need to have like external auditing questions

1:45:33

right like how you can I argue both sides of a thing have I consider point of view can I um and that without these like it's very easy to get lost yeah one

1:45:40

of the biggest issues with the uh we brought up that free speech thing and then the information environment today is I think people have this really bad

1:45:48

default assumption that truth is this good thing

1:45:54

like normatively it's just ontologically truth is good and human minds are designed to seek and validate truthful

1:46:01

things and so when you look at an information environment as long as we have all the information out there and more and more people can add to it and

1:46:07

there's just all the access we have to it that we're like the best answers are always going to like come out and that

1:46:12

is absolutely not the opposite has been the case yeah which obviously has a lot to do with the perverse incentives but

1:46:18

um yeah do you feel like you do you have tips and tricks for yourself to keep

1:46:25

your self in check yeah for sure it's and you said steel Manning yeah one of

1:46:31

them is um you should be able to argue both sides of a position very convincingly um another is that um uh

1:46:38

you you should always the question of like what would it take to convince you that this position isn't correct um for

1:46:44

some topics as I've gotten more more into reading stuff um I I realize like I

1:46:50

don't trust summaries on things a lot like they're very I don't know if there's any immediate that I trust to like summarize like legal stuff like if

1:46:55

it's a Supreme Court decision I have to read it um one thing I noticed is that for a lot of topics unfortunately it's

1:47:00

kind of like a diet and exercise um there's not a shortcut I can't say that anymore actually I guess OIC exists but

1:47:06

prior to OIC um there's not like a shortcut sometimes you just have to like read stuff as boring as it is yeah um

1:47:12

yeah I think um well I think uh the the way I kind of think about it is um I

1:47:20

feel like the Greeks had a formula here they had you know first person epistemics know thyself Know Thy lens

1:47:27

Know Thy bias like know what you what you care about cuz that will be

1:47:33

informing what you decide you know what information you decide to like what facts you cherry pick there's the know

1:47:40

that first person second person which you are already articulating is the be able to articulate the other person's

1:47:46

perspective and then third person is the like actually knowing the world but we usually only focus on third person when

1:47:53

we talk about media literacy or critical thinking but you actually need to like you kind of need all three like you need

1:47:59

to know your own instrument you need to like know the other person's instrument a little bit and then you you know if

## Closing Thoughts and Aspirations

1:48:05

you want to know what is going on you actually need all three of those to some extent yeah so how that uh how that

1:48:11

plays out like I haven't seen that I don't know I'm I'm I'm not in the realm of education so maybe that's being more

1:48:17

incorporated into critical thinking but I do that is something that I've deliberately kind of wanted to design in

1:48:22

to the antidebate even even if it's just like at some point during it just checking in with how you're feeling mhm

1:48:29

and maybe realizing like oh I'm really tense like I'm or I'm feeling like angry or I'm feeling frustrated or I have a

1:48:36

knot in my throat like knowing your emotional reaction is going to be

1:48:42

probably helpful yeah you know absolutely yeah um the red flag is always like um try to free yourself from

1:48:48

your biases or I'm unbiased oh for someone saying that yeah I always tell people like when I like when I'm doing

1:48:56

research if I'm going to listen to somebody want oh listen to this video whatever it's a video like I'll write

1:49:01

like right at the top of I don't like almost everything Joe ran has to say about anything um but this is really

1:49:07

important because there are times where he'll say things that are true and my intuition is I just want to fight against cuz he \[ \_\_ \] said it or the

1:49:13

guy said it but um there are things they say that can be true so I know that I have to be a little bit more careful like Joe ran might say like oh like you

1:49:18

know that 92% of immigrants you know have speeding tickets I'm like \[ \_\_ \] no \[ \_\_ \] ways that every like okay

1:49:24

hold on he says it and if somebody that I agreed with more said it would i' be like oh that's an interesting St maybe it's true so I'll like fact check a

1:49:30

little bit harder on statements from people that I don't like because I know yeah um one thing that I stress this is

1:49:36

one of the most important things um is for a variety of reasons I um am just a

1:49:42

very independent person I don't know if it's upbringing biology whatever but I'm a very independent person and so I have a lot of political Freedom as a result

1:49:48

of that and I'm willing to um endure a lot of political isolation online

1:49:57

fedility to oh I'm very independent um but I try to remind people that like

1:50:03

well I can do that that's because at this point in my career there's a huge reward in the fact that like this is

1:50:08

kind of my brand and I've already incurred all the punishment for it so it's you know whatever like nobody on a political group likes me but in a

1:50:14

person's uh individual life those incentives the social structures can

1:50:19

dictate a lot of your political like if if a new report came out

1:50:25

tomorrow that said uh we just did the the best study in the world and socialism is the best way to do the

1:50:31

government I'm a huge capitalist okay but if that study came out I'd be like oh \[ \_\_ \] it then let's \[ \_\_ \] how do we get to socialism right I don't I I don't

1:50:37

have a moral attachment to capitalism it's the strategy not the goal yeah yeah I don't lose anything saying that if

1:50:43

that came out and Ben Shapiro saw it even if he knew it was true Ben Shapiro is not thinking just like okay well

1:50:49

what's the most true thing he's got to think okay am I ready to sacrifice half my audience totally yeah which is you well that's amazing that's a miracle

1:50:56

that you've built an audience like that um me thing yeah I mean no seriously

1:51:01

because that's the that's the um like often what I see happen is the like

1:51:08

someone an influencer who's like moving let's say in who's kind of like staking a like kind of like a synthesis

1:51:15

Position will sometime like some they'll often get kind of canceled from whatever

1:51:21

try it's like if you were on the left but you're you were canceled by the left but you're not on the right you were on

1:51:26

the right you're canceled by the right you're not on the left so where are you kind of in the synthesis place but often they'll get stuck resenting the tribe

1:51:32

that canceled them and then they'll just get and why I left the left and then yeah and then and then that devolves

1:51:38

into this like vicious cycle of just like anti whatever anti the thing that I was canceled from whereas you know I

1:51:45

think you're in a much better position where you can actually just you and your audience can kind of like continue to

1:51:51

like I don't know it's of like a virtuous cycle towards I would say like greater levels

1:51:56

of integration like you can actually include you are in a very good position to include more perspectives than Ben he

1:52:04

can't like he just said like if that report comes out so it's good for me but I don't know how realistic it for all of

1:52:11

us yeah but I just don't know how realistic it is for most people to occupy that position because the support

1:52:18

that you get from tribal stuff is really big yeah and necessary I think for a lot

1:52:23

of people so like it's hard to know though it's actually hard to know because I don't think Joe Rogan is very

1:52:29

politically pigon H holdable I think he's very much bought in by the magga crowd actually I know that to be true

1:52:35

yeah unfortunately but he but I still like he's still like here's another

1:52:41

question you can add to your list of like how to get you know it's like what two opinions do you hold do are that are

1:52:47

rarely held together and I think question he has I don't think he those

1:52:55

oh this is almost vict steinan I actually I I think he does can add that question to your to your yeah to your

1:53:01

toolbox I think he does have that but I think that um I tried to stress this I remember two years ago I was trying to

1:53:07

this in front of an audience in New York and everybody's booing at me and it's funny um people for a long time they

1:53:12

fell into this stupid Paradigm of like um they would have these conferences they bring people like look at how many people from the right and left were

1:53:18

bringing together like there are so many people from so many different backgrounds that were bringing together and there was this illusion this Unity between the right and the left and I saw

1:53:25

this like years ago and I think anybody was like there is no this is you guys are 100% ideological congruence you

1:53:32

think that you're bringing people from the left and the right together but it's because the left and right beliefs you

1:53:37

have are very Outer Perimeter beliefs but you are actually wholly unified in

1:53:43

your anti-establishment beliefs and over the past several years especially with this whole like populist R kind of yeah

1:53:50

it's it's really become like a establishment versus anti-establishment game so if I were to ask somebody like

1:53:55

Joe Rogan or Tim P even does this but like you would ask that question what two commonly or what two beliefs do you have aren't commonly held together Joe

1:54:02

Rogan might say something along the lines of like um like I support Donald Trump or I think he's you know got a

1:54:07

good idea here for this conservative stuff but I'm also like really big on like weed legalization um which conservatives traditionally like weren't

1:54:13

in favor of uhuh and like that might seem like okay that kind of makes sense but if you look at where the world is

1:54:19

now or if you actually analyze like where the political groups are now probably not as different there's a realignment happening right now a little

1:54:25

bit Yeah because of the which is so great it's like you know I I think it makes wiggle room for new things to

1:54:31

happen I am very Pro the realignment as like weird as it might be that Dick Cheney endorsed kamla and that RFK and

1:54:39

tsy gab went over to Trump like I think it allows room for new things to happen because it's not as just like it's not

1:54:47

as cleanly polarized right it's I mean I I feel like I feel like what's happening is um I I I find this moment to be

1:54:55

exciting from synthesis perspective wish I want to agree with you okay but I totally disagree but I wish I was true

1:55:01

like I think it would be more interesting if it was like um if it was like uh like like Hillary Clinton and um

1:55:08

who's your like Marco Rubio or Ted like you have like these are diametrically

1:55:13

differently opinioned people and to see them come together and agree on something would be interesting but when I see um like Tulsi Gabbert and RFK

1:55:21

these are just solidly anti-establishment people and the fact that they would align with like people on the right who are also right now

1:55:26

solidly anti-establishment I guess in my mind it looks like a fox kind of like realignment when in reality these people

1:55:33

are like aligned on like because even toally and maybe that but maybe that is the realignment is instead of

1:55:38

progressive conservative it's establish anti-establishment which I think is like I think that could be helpful maybe yeah

1:55:46

for for for for a season sure you know um I I I like want to I just want to

1:55:52

share this one anecdote that you might appreciate given that um you said you've like you've like you've already

1:55:58

alienated everybody there's this um so but okay maybe this is like the last nerdy thing to share and then um so

1:56:05

there's this framework that um forgive me it's going to sound okay so it's called the spiral dynamics of

1:56:10

Consciousness have you ever heard of this I have not but go ahead okay so the idea is um so he the person who

1:56:17

developed it was actually a contemporary of maslo do you know maslo hierarchy

1:56:22

so so this guy his name is Claire Graves and he developed this system for how

1:56:29

human beings evolve over time both human beings like an individual human being and Humanity over the course of

1:56:35

evolution and he identified different stages of evolution and Masa himself was

1:56:41

like damn this is amazing but he died before he was able to really publish it so we are more left with maslo than we

1:56:47

are left with spiral dynamics of Consciousness anyway um and it and it's it does it's strikes it's like anyone

1:56:53

who's kind of like antih hierarchical won't love this thing because like what do you what do you mean like we go through different phases and some people

1:56:59

are more evolved in others it's like yeah that is what I'm saying like PE like like civilizations that believe in

1:57:07

human rights are more evolved and we can just say that and if you can't say that then what do you really then you can't

1:57:13

say anything then why why do you care about anything cuz you can't actually make a claim about any value being more

1:57:18

valuable than another anyway I usually the funny thing on that just real quick that that believe that I think that's always immediately self-defeating

1:57:24

because the same people that will say one civilization or culture can never be better than another one are always people that are pushing for cultural or

1:57:29

civilizational change like well isn't the civilization that you're pushing for better than the one we're now which is very hypocritic yeah it's like every

1:57:36

yeah nothing is better than anything else except for the fact that what I'm saying is better okay but that but that by the way is a stage that whole thing

1:57:43

is a stage in the evolution it's called the sense so there are different stages and that one is um I'm going to just

1:57:50

super super simplify let's just say say because what's helpful about this is

1:57:55

that it um I mean there's so many things that are helpful but part of it is like we don't have to like a 9-year-old is

1:58:01

not a defective 12-year-old right we can just like appreciate a nine-year-old for being a nine-year-old in a you know and

1:58:07

we can kind of understand but um one nice thing that this framework does is that it do instead of thinking in terms

1:58:14

of left and right and red and blue there are actually different stages we're working with and if we were going to

1:58:20

collapse them let's say there's the traditional modern and then postmodern

1:58:26

and postmodern is and we could say like shadow of postmodern is woke gone off the deep end but the non Shadow the

1:58:32

light of it is like thank you for waking us up to the plight of marginalized people everywhere like thank you for

1:58:37

introducing the oppressor oppressed frame is it always the most relevant frame with which to see a given situation no but thank you because we

1:58:44

needed that frame to come online but anyway so one it's it's instead of like

1:58:50

red and blue what you what spiral Dynamics kinds of like allows you to see

1:58:55

is uh is that it's actually it's it's it's it's it's traditional and Progressive and modern is split and the

1:59:02

modern that is with the traditional is like the more establishment side and the

1:59:08

modern that is with of of that wing and the modern that's with the progressive is the is the is the establishment side

1:59:15

of that Wing you could say does that make sense uh keep talking well it's it's it helps us understand why there's

1:59:21

a Schism in the right and in the left because the right is a mixture of

1:59:27

traditional and modern and the left is a mixture of modern and Progressive okay

1:59:32

okay but let's just throw that that out the window for a second because the thing that I actually wanted to tell you was okay so there's a joke in spiral

1:59:39

dynamics that like okay what if you invited them all to a party what would happen so the traditional and the modern

1:59:45

Progressive like can't stand each other right because like the traditional is like try is like you know we shouldn't

1:59:50

be drinking and everyone should be whatever and then the modern is like is like doing like keg like trying to defeat everybody with the keg stands and

1:59:56

the and the progressive is like oh but we need safe words and consent blah blah blah and the integral the integral which

2:00:02

is the like is the is the is the instead of my way right your way is wrong is the

2:00:08

like wow look at all these ways and which one is useful in different circumstances and some of them are better and some of them are worse but

2:00:13

I'm able to hold them all together nobody they don't understand the

2:00:18

integral person at the party but they dis like them the least okay so that's

2:00:25

that's that's what you gain you're like least disliked by the majority of people

2:00:31

who cannot agree on anything else gotcha congratulations that was a lot of okay to get to the yeah well I understand the

2:00:38

how that works but I actually just kind of feel like the most disliked by everybody but thanks for the no but you're you're probably Le you're less

2:00:44

disliked than somebody that they really hate no yeah that's probably true yeah so you're you're least disliked sure

2:00:51

yeah even if I am the most disliked the way that they most dislike me is always by invoking the worst type of person

2:00:57

that they're trying to associate me with but if they were fighting the other person I would never be invoked as like

2:01:02

you're just like sorry I'll take that there you go congratulations thanks a lot um any other jokes thoughts

2:01:12

Concepts I mean there's an Infinity but no I think we can leave it at that if uh

2:01:17

if you're interested in um spiral Dynamics I can definitely send you

2:01:22

sure um I I find yeah I find these things um very helpful yeah but um I

2:01:30

guess before we close out is there who do you have like a dream person that like if I could talk to or do an anti-

2:01:36

debate with you um so yeah if you could

2:01:42

\[Music\] um um I mean I think I think that's more

2:01:48

a question for you like I do want I I do want one about AI between probably

2:01:54

between Elon and someone his name is Daniel do you know who Daniel

2:02:01

schmachtenberger is yeah of course okay no I don't okay well so I do I think I

2:02:06

think I think AI is an urgent one that needs to happen Okay um but I but

2:02:11

honestly I think that's a better question for you is just like who yeah who is it time I it may be kind of weird

2:02:19

to say it this way but it's like who is it time to integrate with who is the Trump I need kid I don't think I don't I

2:02:27

don't I don't I don't think he's really like up to the task I would do it with someone who you can really who can like

2:02:33

really engage and who we like it will be an edifying experience

2:02:40

for everyone sure okay um like who yeah who so I think the people you've named

2:02:47

are perfect like you and Ben Shapiro on Free Speech or whatever your issue of choices mhm and I think it will do like

2:02:55

a real service okay yeah um people are looking for you where do you want to direct

2:03:02

people to yes people can find me on Twitter at STP you can find faces of X

2:03:08

at facesof x.org and uh uh I'll I'll keep you posted when

2:03:13

there's an antidebate ready to be antidebated yeah if you need me to moderate one or a debate one just let me

2:03:20

I would love both I would and I actually I have a a friend who I told I was coming here and she wants to host a live

2:03:26

one at her house in La so la a lot so sounds good okay cool thanks lot for

2:03:32

joining me um yeah thank you thank you and thank you for yeah for making room

2:03:38

for different perspectives it's really helpful and we need it so I'm grateful to you cool thanks

2:03:45

\[Music\]

2:03:51

news is divided ground news puts it back together so you can see how many sources

2:03:57

are reporting on any breaking story where they fall on the political Spectrum how reliable they are and who

2:04:04

owns them compare headlines and read full articles to see which details are

2:04:10

prioritized exaggerated or left out entirely because the more we understand

2:04:15

the media the more we'll understand each other visit ground. newws to learn more

## Concepts

| Name | Weight |
| ---- | ------ |

{ .block-language-dataview}
